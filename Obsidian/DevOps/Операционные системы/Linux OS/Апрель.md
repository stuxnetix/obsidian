
## 1. Какое имя и UID администратора?

 $ root: UID 0.

## 2. Как посмотреть все файлы в каталоге, включая скрытые?

$ ls -la

## 3. Какая команда в Unix/Linux удаляет каталог со всем его содержимым?

Удаление каталога и всего его содержимое без подтверждения: rm -rf.

$ rm -rf directory_name

## 4. Какая команда в Unix/Linux показывает свободную/используемую память? Существует ли свободная память в Linux?

$ free -h

## 5. Как найти строку "my konfu is the best" в файлах каталога рекурсивно?


$ grep -r "my konfu is the best" /path/to/directory


## 6. Как подключиться к удаленному серверу или что такое SSH?

SSH (Secure Shell) - это протокол, используемый для удаленного управления системами и приложениями через сеть. Он обеспечивает безопасное зашифрованное соединение между локальной и удаленной системой.

$ ssh username@hostname_or_ip

## 7. Как получить все переменные окружения и как их можно использовать?

Переменные окружения обычно используются для хранения настроек системы или отдельных программ. Например, переменная окружения PATH содержит пути к каталогам, в которых shell ищет исполняемые файлы. С помощью переменных окружения можно также передавать настройки в дочерние процессы.

$ printenv

$ printenv HOME

Изменить переменные окружения можно с помощью команды export.

$ export VARNAME="value"

Если вы хотите, чтобы эти изменения были постоянными, вы должны добавить эту команду в ваш файл профиля, обычно .bashrc или .bash_profile в вашем домашнем каталоге.

$ echo 'export TEST_VAR="This is a test variable"' >> ~/.bashrc

и затем перезапустите shell или выполните команду source ~/.bashrc, чтобы применить изменения.

$ source ~/.bashrc

## 8. Как добавить пользователя без прав входа в систему?

$ useradd -s /usr/sbin/nologin <имя пользователя>

## 9. Как добавить/убрать пользователя в/из группы?


sudo usermod -a -G groupname username

sudo gpasswd -a username groupname

sudo deluser username groupname

## 10. Как установить email для пользователя root?

sudo nano /root/.forward

Это откроет файл .forward в текстовом редакторе nano. В этот файл вы можете ввести email адрес, на который вы хотите перенаправлять всю почту пользователя root.

Пожалуйста, учтите, что вам может потребоваться установить или настроить почтовую систему на вашем сервере, чтобы это работало правильно.

## 11. Что содержится в файле /etc/services?

/etc/services в Unix/Linux системах представляет собой базу данных служб, используемых различными приложениями. Он устанавливает связь между названиями служб для TCP и UDP и их

ftp     21/tcp
ssh     22/tcp
telnet  23/tcp

## 12. Что такое модуль ядра Linux?

Модуль ядра Linux - это кусок кода, который может быть загружен и выгружен из ядра на лету, без необходимости перезагружать всю систему.

Модули используются для расширения функциональности ядра Linux без необходимости прямой модификации исходного кода ядра. А также это позволяет уменьшить размер ядра, путем загрузки только необходимых модулей.

Например, для поддержки некоторого оборудования (графических адаптеров, сетевых карт) или файловых систем можно использовать модули. Они загружаются только при необходимости и могут быть выгружены, когда их функции больше не нужны.

Модули ядра обычно управляются с помощью команд insmod (для вставки модуля ядра), rmmod (для удаления модуля ядра) и lsmod (для отображения списка текущих модулей ядра).

## 13. Расскажите по шагам как загрузить систему в однопользовательском режиме для решения проблем.

Через GRUB. Или

$ sudo systemctl set-default rescue.target && sudo systemctl reboot

$ sudo systemctl set-default graphical.target


## 14. Расскажите по шагам как вы будете решать проблему с ошибкой 404 в веб-приложении, которое вы обслуживаете.

404 означает что система не смогла предоставить вам запрашиваемый ресурс. В случае, если речь идет про статический файл (страница, рисунок и тп) — мы должны убедиться что он присутствует на сервере и веб сервер имеет к нему доступ. Для этого необходимо проверить конфигурацию веб сервера, права доступа, название файла и полный путь до него  ( возможно в нем или в описании пути в url ссылке допущена ошибка). В случае если ошибка появляется при генерации динамического ресурса — необходимо проверить передаваемые параметры и сценарии генерации страницы, хотя скорее в таком случае мы получили бы ошибку 5хх.


## 15. **Как перенаправить вывод STDOUT и STDERR в баше? (How to redirect STDOUT and STDERR in bash? (> /dev/null 2>&1))**

> file — Направить стандартный поток вывода в файл. Если файл не существует, он будет создан, если существует — перезаписан сначала

2> file — Направить стандартный поток ошибок в файл. Если файл не существует, он будет создан, если существует — перезаписан сначала

>>file — Направить стандартный поток вывода в файл. Если файл не существует, он будет создан, если существует — данные будут дописаны к нему в конец

2>>file — Направить стандартный поток ошибок в файл. Если файл не существует, он будет создан, если существует — данные будут дописаны к нему в конец

&>file или >&file — Направить стандартный поток вывода и стандартный поток ошибок в файл. Другая форма записи: >file 2>&1

## 16.Что делают следующие команды и как вы можете их использовать? (What do the following commands do and how would you use them?): tee, awk, tr, cut, tac, curl, wget, watch, head, tail**

- tee — читает со стандартного ввода (stdin) и выводит на стандартный вывод (stdout) и в указанный файл. Очень удобно когда вашему скрипту нужно и лог писать, и интерактивно сообщения на экран отправлять
- awk — потоковый редактор который помогает управлять текстом при выводе. Я например использую его для удобного оперирования многоколоночным текстом.
- tr — утилита для управления символами во входящем потоке текста. Подставлять или удаляет указанные символы
- cut — утилита обработки текста, позволяющая выбирать колонки из текста или поля из строки
- tac — команда, обратная команде cat — выводит файл (или конкатенацию файлов) но задом-наперед
- curl клиентская программа для взаимодействия с серверами, поддерживающими формат url обращений, обычно веб серверами. Лично я применяю ее как консольный клиент для работы с веб серверами- проверить доступность, статус, дернуть api и тд.
- wget — утилита для сетевой загрузки файлов.
- watch — утилита позволяющая отслеживать вывод не интерактивной программы, запуская ее многократно, с указанным интервалом времени. Удобно когда вы хотите посмотреть какой то процесс в динамике — например “watch cat /proc/mdstat”
- head — утилита обработки текста. Вывод указанное число строк с начала файла
- tail утилита обработки текста. Вывод указанное число строк с конца файла. Может работать в режиме постоянного чтения и вывода на экран информации, дописываемой другим процессом в конец файла. Удобно смотреть логи в режиме реального времени



## 17. Что такое пакетный фильтр и как он работает?

>Пакетный фильтр — обобщенное название системы фильтрации трафика в linux-based операционных системах. Подсистема ядра, занимающаяся  анализом и обработкой всех входящих сетевых пакетов заданным администратором правилам. Трафик либо пропускается, либо отбрасывается, либо каким-то образом маршрутизируется, либо логируется. Так же возможны некоторые комбинации этих действий.


Пакетный фильтр - это подсистема или программа в операционной системе, которая отвечает за управление сетевыми пакетами при их пересылке между различными подсетями.

Пакетный фильтр работает на уровне сетевого интерфейса и позволяет или запрещает передачу пакетов на основе заданных правил. Эти правила, известные как правила фильтрации пакетов, обычно определяются на основе атрибутов пакета, таких как IP-адрес источника и назначения, порт, протокол (TCP, UDP, ICMP и т.д.), и, в некоторых случаях, содержимого самого пакета.

Пакетный фильтр обычно используется в операционной системе для настройки межсетевого экрана или брандмауэра. В Linux, например, пакетный фильтр реализован в ядре и может быть настроен с помощью утилиты iptables, nftables, или firewall-cmd (в случае firewalld).

Процесс работы пакетного фильтра таков:

Когда пакет отправляется или получается через сетевой интерфейс, пакетный фильтр сравнивает атрибуты пакета со своим набором правил фильтрации.
Если пакет соответствует одному или более правилам, применяется соответствующее действие (например, разрешить передачу пакета или блокировать ее).
Если пакет не соответствует ни одному из правил, применяется действие по умолчанию (обычно блокировка).
Пакетные фильтры являются ключевым элементом обеспечения безопасности сети, так как они контролируют, какие пакеты могут передаваться через сетевые интерфейсы, что помогает предотвратить нежелательный трафик или атаки.

## 18. Что такое виртуальная память?


>Метод управления памятью, позволяющий выделить процессу памяти больше, чем на самом деле это возможно сделать. Программе “выделяется” некий пул страниц памяти, которые в дальнейшем могут быть перемещены на диск,  в специализированную область подкачки, либо наоборот, “подняты” из нее в случае необходимости.

Виртуальная память - это методика, которую используют операционные системы для расширения доступного объема памяти, делая часть жесткого диска вычислительной системы доступной как будто она является дополнительной оперативной памятью.

Когда оперативная память (RAM) начинает заполняться, операционная система может перемещать некоторые данные из RAM на жесткий диск в область, называемую файлом подкачки или свопом. Виртуальная память позволяет вашему компьютеру выполнять больше задач, чем это возможно при использовании только физической RAM.

Основными преимуществами использования виртуальной памяти являются следующие:

Она позволяет запускать больше программ, чем позволяет физическая память (RAM).
Она изолирует каждую работающую программу, делая ей видимой только свои данные и код, что улучшает безопасность.
Недостатком использования виртуальной памяти является то, что доступ к данным на жестком диске намного медленнее, чем в оперативной памяти. Кроме того, чрезмерное использование виртуальной памяти может привести к вероятности "трэшинга" (thrashing), когда система тратит больше времени на перемещение данных между RAM и диском, чем на выполнение самой программы.

В Linux, виртуальная память используется для того, чтобы каждому процессу предоставить впечатление, что у него есть собственное выделенное пространство в оперативной памяти (RAM). К тому же, часть виртуальной памяти может располагаться на жестком диске в пространстве подкачки (swap space), что позволяет системе использовать больше памяти, чем физически доступно в машине.

Преобразование адресов: Виртуальная память Linux использует механизм преобразования виртуальных адресов в физические адреса. Это позволяет каждому процессу вести себя так, как будто у него есть доступ к полному объему физической памяти, независимо от других процессов.
Подкачка (Swap): При нехватке свободной физической памяти, Linux может использовать пространство подкачки (swap space) на жестком диске как дополнительную виртуальную память. Куски памяти, которые не используются в данное время, переносятся в пространство подкачки, освобождая физическую память для текущих нужд. Swap обычно медленнее, так как дисковые операции заметно медленнее операций с RAM.
Управление памятью: Linux использует различные механизмы управления виртуальной памятью, такие как "lazy allocation" (выделение памяти при первом обращении), "copy-on-write" (копирование при записи) и страничное замещение (swap out), для оптимизации использования памяти.
Важно отметить, что хотя виртуальная память и увеличивает общий доступный объем памяти, интенсивное использование пространства подкачки может снижать производительность, поскольку дисковые операции обычно намного медленнее, чем операции в RAM.

## 19. Что такое swap и для чего он используется?


>Специально выделенная область диска или файл, использующийся для расширения виртуального адресного пространства памяти ( см виртуальная память) за счет места на дисковом устройстве.

Swap — это пространство на жестком диске, которое используется как виртуальная память в операционной системе. Swap применяется, когда объем физической оперативной памяти (RAM) исчерпан.

Если операционная система (например, Linux) нуждается в большем объеме памяти, чем доступно в момент выполнения, она производит операцию подкачки (swapping), перемещая часть данных из ОЗУ в swap-пространство. Это освобождает ОЗУ для выполнения сопутствующей задачи. Когда эти данные снова понадобятся, они будут возвращены в ОЗУ из swap-пространства.

Обратите внимание, что использование swap может существенно замедлить работу системы, так как скорость чтения и записи на жестком диске значительно ниже, чем в оперативной памяти. Соответственно, swap лучше использовать как резервный вариант для временного хранения данных, а не как замену ОЗУ.

В большинстве Linux-систем размер и использование swap-пространства можно настроить с помощью утилиты swapon и swapoff. Смежными темами являются "swapiness" (параметр, определяющий агрессивность использования swap) и создание swap-файлов, вместо или наряду с использованием swap-раздела.


Вот некоторые из проблем, которые могут возникнуть при использовании swap в Linux:

Снижение производительности: Доступ к жесткому диску в разы медленнее, чем к оперативной памяти. Поэтому при активном использовании swap принципиально может снизиться производительность системы.

Состояние "трэшинга" (thrashing): Если системе приходится постоянно перемещать данные между памятью и swap, это может вызывать состояние, известное как thrashing, когда значительная часть системного времени тратится на своппинг данных, а не на выполнение полезной работы.

Потеря данных: В случае неожиданного выключения питания данные, хранящиеся в swap, могут быть утеряны. В отличие от данных в оперативной памяти, которые теряются при любом выключении, данные в swap сохраняются между сеансами, и сбой может привести к более длительной потере данных.

Увеличенное износ SSD: Операции записи могут ускорить износ дисков SSD. Если ваш swap размещен на SSD, активное использование swap может привести к его раннему выходу из строя.

Занимает место на жестком диске: И, наконец, swap занимает место на вашем жестком диске, которое могло бы быть использовано для хранения других данных.

Решению этих проблем обычно помогают планирование использования памяти, увеличение объема физической памяти (если возможно) и настройка параметров использования swap.


## 20. Планирование использование памяти

Планирование использования памяти может включать следующие стратегии и подходы:

Определение объема памяти, необходимой для приложения: Оцените, сколько памяти вашему приложению потребуется для нормальной работы. Это может помочь вам правильно разместить процессы и избежать ситуаций, когда процессу не хватает памяти.

Оптимизация кода: Попытайтесь оптимизировать свой код, чтобы он потреблял меньше памяти. Это может включать в себя повторное использование объектов, удаление ненужных данных из памяти и использование более эффективных структур данных.

Настройка уровня свопинга: В Linux вы можете настроить параметр swappiness (уровень свопинга) для определения того, насколько активно система будет использовать область подкачки. Большое значение этого параметра приводит к активному использованию swap, а маленькое — к тому, что swap используется только как последний вариант.

Использование контейнеров или виртуальных машин: Использование контейнеров или виртуальных машин может помочь изолировать процессы друг от друга, позволяя контролировать, сколько памяти каждый процесс может использовать.

Мониторинг использования памяти: Регулярный мониторинг использования памяти может помочь обнаружить проблемы раньше и принять соответствующие меры. Вы можете использовать средства мониторинга, такие как free, top, vmstat, htop и другие, для отслеживания использования памяти в реальном времени.

Создание резервного пространства на диске: Резервное дисковое пространство может быть использовано в случае, если памяти становится недостаточно и начинает использоваться swap. Это может помочь избежать ситуаций, когда системе не хватает места для размещения страниц памяти в области подкачки.

Использование средств уровня языка программирования для управления памятью: Некоторые языки программирования предоставляют средства для управления памятью, включая автоматическую сборку мусора, пулы памяти и другие исполнители ручного контроля использования памяти. Хорошее понимание этих средств может помочь эффективно управлять памятью.

## 21. Что такое A-запись, NS-запись, PTR-запись, CNAME-запись, MX-запись?

A-запись (Address record): A-запись - это запись DNS, которая связывает доменное имя с IP-адресом версии 4. Например, если у вас есть веб-сайт с доменным именем www.yoursite.com, его A-запись указывает на IP-адрес сервера, который хостит этот веб-сайт.

NS-запись (Name Server record): NS-запись - это запись DNS, которая указывает на серверы имен (DNS-серверы), ответственные за данную зону DNS. Они используются для делегирования части пространства имен другому DNS-серверу.

PTR-запись (Pointer Record): PTR-запись используется для обратного DNS-разрешения, т.е. для преобразования IP-адреса в доменное имя. Это противоположность A-записи, которая преобразует доменные имена в IP-адреса.

CNAME-запись (Canonical Name record): CNAME-запись используется для создания псевдонима для доменного имени и его связывания с реальным, каноническим доменным именем. Например, вы можете иметь доменное имя www.yoursite.com, которое на самом деле является псевдонимом для yoursite.hostingcompany.com.

MX-запись (Mail Exchange record): MX-запись указывает на серверы, ответственные за обработку почты для данного домена. Когда вы отправляете электронное письмо, ваш SMTP-сервер использует MX-запись в DNS, чтобы узнать, куда доставить письмо.


>Ресурсные записи системы dns:

- A — основная запись, ставящая человеко-читаемое имя в формате fqdn в соответствие ip адресу.
- NS — ресурсная запись, содержащая информацию об ip адресе dns сервера, обслуживающего данный домен
- PTR — т.н. “обратная” ресурсная запись, противоположная А, ставящая в соответствие ip адресу имя в формате fqdn
- CNAME — ресурсная запись- псевдоним, позволяющая создать одноуровневую переадресацию, задавая соответствие имя-имя (например для сервера srv.example.com, функциональный псевдоним mail.example.com)


Эти записи хранятся на DNS-серверах в файле зоны. Файл зоны — это текстовый файл, который содержит информацию о пространстве имен для конкретной зоны. Он содержит различные типы данных DNS, включая A, NS, PTR, CNAME и MX записи.

DNS (Система доменных имен) — это иерархическая и распределенная система управления, которая используется для преобразования человекочитаемых доменных имен в числовые IP-адреса числах, понятных для компьютеров, и наоборот.

Когда вы вводите URL-адрес в своем браузере, ваш комьютер обращается к вашему DNS-серверу и запрашивает соответствующую запись, чтобы узнать IP-адрес, связанный с этим доменом для следующего подключения.

Такое разделение позволяет распределить нагрузку, обеспечивает более высокую доступность и масштабируемость системы доменных имен.


## 22. **Что такое A, NS, PTR и CNAME записи?**


Да, кроме уже упомянутых записей, существуют и другие типы DNS записей (Resource Records, RR). Вот некоторые из них:

SOA (Start of Authority): SOA-запись определяет базовые параметры зоны и содержит информацию о первичном DNS-сервере.

TXT (Text Record): TXT-записи обычно используются для описания домена и содержат произвольный текст. Они также используются для таких вещей, как верификация владения доменом и SPF-записи для проверки подлинности электронной почты.

SRV (Service Record): SRV-записи используются для указания расположения серверов для определенных сервисов, например XMPP, SIP, IMAP и других.

AAAA (IPv6 Address record): AAAA запись делает то же, что и A-запись, но для IPv6-адресов.

CAA (Certification Authority Authorization): CAA-записи позволяют доменным владельцам указывать, какие сертификационные центры могут выдавать сертификаты для их доменов.

Все эти записи служат различным целям и используются для разделения ответственности и управления различными аспектами пространства имен DNS.


## 23. Что такое расщепление горизонта в терминах dns? Split-Horizon DNS


>Прием, используемый для разрешения одного и того же DNS имени в разные ( по смыслу) IP адреса, например mail.example.com изнутри сети направит клиентов непосредственно на внутренний почтовый сервер, а снаружи, пользователи будут направлены на сервер, стоящий перед почтовиком и выполняющий роль антивирусного и спам сканера.

Split-Horizon DNS, или Split-View DNS, это метод конфигурации DNS-сервера таким образом, чтобы одни и те же имена доменов могли разрешаться в разные IP-адреса в зависимости от местоположения клиента, делающего запрос. Это часто используется для разделения поведения внутренних и внешних запросов.

Например, компания может использовать разделение горизонта DNS для того, чтобы запросы внутри корпоративной сети разрешались в приватные IP-адреса домена, в то время как запросы извне корпоративной сети разрешались в публичные IP-адреса.


В данном примере, внутренние клиенты из подсети 192.0.2.0/24 получат DNS-данные из файла internal-db.example.com, в то время как все остальные клиенты получат данные из файла external-db.example.com.

## 24. Что такое sticky bit?

Sticky bit это специальный тип разрешений, доступный для Unix-like операционных систем. Если sticky bit установлен для каталога, файлы внутри этого каталога могут быть удалены или переименованы только их владельцами, владельцем каталога или root-пользователем.

Это полезно для каталогов, в которых множество пользователей имеют права на запись, таких как /tmp, для предотвращения удаления или переименования файлов, которые принадлежат другим пользователям.

Чтобы установить sticky bit на каталог, используйте команду chmod с опцией +t, как показано ниже:

chmod +t /directory/path

Если sticky bit установлен, вы увидите t в конце ряда разрешений, например: drwxrwxrwt.

## 25. Что делает установленный на файл immutable bit?

Установка immutable bit на файл в Unix-like системах не позволяет удалять, переименовывать, изменять содержимое или изменять атрибуты файла, даже если вы в системе под пользователем root. Это может быть полезным для предотвращения случайного удаления или изменения критически важных системных файлов.

Вы можете установить immutable bit на файл с помощью команды chattr:

sudo chattr +i /path/to/file

lsattr /path/to/file

Immutable bit является важным инструментом защиты системы. Да, root или пользователь с sudo-привилегиями могут снять этот бит, однако его основной смысл как раз в защите от случайных и потенциально вредоносных действий.

Отметка файла как immutable означает, что даже пользователь с правами root не может изменить или удалить этот файл, пока бит не будет снят. Это предотвращает случайное удаление или изменение важных системных файлов, которые могут повредить систему.

Также это может затруднить работу вредоносного ПО или злоумышленника, получившего root-доступ к системе, поскольку им придётся сначала снять этот бит, что может быть замечено системой безопасности.

## 26. Какая разница между символическими и жесткими ссылками? Что произойдет если удалить символическую/жесткую ссылку?

Жесткая ссылка: Это просто дополнительное имя для существующего файла на Unix или Linux. Фактически существующие файлы хранятся в inode и управляются по ссылке. Есть два имени файла, ссылающихся на одну и ту же область (inode), и вы можете назвать это вторым именем. Если вы удалите одно имя, другое имя все еще будет ссылаться на область диска. Тем не менее, жесткие ссылки не могут ссылаться на другие файловые системы или каталоги.

Символическая ссылка (или мягкая ссылка): Это аналогично ярлыку в Windows. Он не содержит данных файла, но указывает на другой файл или каталог. Если вы удалите символическую ссылку, это никак не повлияет на целевой файл или каталог. Однако, если удалить целевой файл, символическая ссылка будет битой.

Хардлинк — это по сути имя файла, символическое значение, ссылающееся на значение inode в файловой системе. Именно поэтому нельзя создать хардлинк на другой раздел. Хардлинков может быть создано более одного — это будут разные имена одного и того же файла. До тех пор пока существует хотя бы один хардлинк, файл существует.

Софтлинк это файл который просто внутри себя содержит указание на другой файл ( его имя). поэтому софтлинки являются более гибким решением, например могут указывать на файл, хранящийся на другой файловой системе), однако если оригинальный файл удален, симлинк остается и становится не рабочим.


## 27. **Что такое айнода и что хранится в ней?**

Структура данных файловой системы в которой хранится информация о файле ( по одной айноде на файл), такая как:

- Блок данных с которого файл начинается
- Дата создания, изменения
- Права доступа
- Владелец

Имя файла не хранится в айноде — это хардлинк



Inode (индексный узел) — это структура данных в Unix и Unix-like файловых системах, которая описывает атрибуты файла или каталога.

В Inode хранится следующая информация:

- Размер файла.
- Устройство, на котором файл хранится.
- Права доступа к файлу, его владелец и группа.
- Время последнего доступа, изменения и модификации.
- Ссылки на блоки диска, где хранятся данные файла.
- Количество жестких ссылок на файл.
- Флаги файла и его версия (только в некоторых системах).
- Самое главное: Inode не хранит имя файла. Имена файлов и их связи с Inode хранятся в каталогах.

Также стоит отметить, что каждый файл в Unix и Unix-like системах имеет свой уникальный номер Inode на каждой файловой системе.



## 28. Как принудительно запустить проверку файловой системы при следующей перезагрузке linux

На Linux, проверку файловой системы при следующей загрузке можно принудительно инициировать с помощью команды "fsck". Однако, так как эта операция может быть опасной для уже запущенной системы, так как может породить повреждение данных, рекомендуется использовать утилиту "touch" для создания файла forcefsck в корневом каталоге. Это сообщит системе о необходимости выполнения проверки файловой системы при следующей загрузке.

Вот как это можно сделать:

$ sudo touch /forcefsck

После выполнения этой команды и перезагрузки системы, процесс fsck автоматически начнется.


- Создать в корне пустой файл: touch /forcefsck — его наличие переопределяет все настройки для fsck в файле /etc/fstab и заставляет систему принудительно проверить корневую файловую систему при запуске. После успешной проверки файл удаляется
- Использовать команду tune2fs -c 1 /dev/sdb1 чтобы включить проверку файловой системы на sdb1 при следующей загрузке.


## 29. Что такое SNMP и для чего он используется?

SNMP (Simple Network Management Protocol) - это стандартный интернет-протокол для управления устройствами в IP-сетях на основе TCP/IP. Он используется в основном для мониторинга сетевых устройств и их рабочего состояния.

SNMP может собирать различные данные о работе устройств, такие как использование процессора, использование RAM, использование сети, счетчики ошибок и многое другое. Эта информация может быть полезна для анализа работы сети и выявления проблем.

В работе SNMP участвуют две основные компоненты: агент и менеджер. Агент - это программа, работающая на мониторимом устройстве и собирающая информацию о его состоянии. Менеджер - программа, которая связывается с агентом и собирает полученную информацию.

Пример использования SNMP может выглядеть так:

$ snmpget -v2c -c public 192.168.1.1 1.3.6.1.2.1.1.5.0

Эта команда запрашивает имя устройства (1.3.6.1.2.1.1.5.0) у агента SNMP на устройстве с IP-адресом 192.168.1.1. Версия протокола здесь - 2c, а "public" - это общедоступное имя сообщества.

>simple network management protocol. переводить я думаю не нужно) Является стандартом дефакто в мире сетевого мониторинга, позволяя снимать различные метрики с хостов, устройств и любых объектов, которые могут быть подключены к сети и на которых производитель реализовал поддержку этого протокола.


## 30. Что такое уровень запуска и как узнать текущий?



Уровень запуска (runlevel) в Unix-подобных операционных системах, таких как Linux, определяет общее состояние системы и то, какие процессы и сервисы должны быть запущены. Например, один уровень запуска может означать, что система в полностью многоюзерском режиме с графическим интерфейсом, в то время как другой уровень может быть ограничен однопользовательским режимом для обслуживания или восстановления.

В Linux отсутствуют строго определенные уровни запуска. Они могут слегка различаться в зависимости от дистрибутива, однако обычно соответствуют следующим параметрам:

0: Остановка системы
1 или S: Однопользовательский режим
2: Неполный многопользовательский режим, без поддержки сети
3: Полный многопользовательский режим, без графического интерфейса
4: Неопределен
5: Полный многопользовательский режим, с графическим интерфейсом
6: Перезагрузка системы
Чтобы узнать текущий уровень запуска в Linux, вы можете использовать команду runlevel.

$ runlevel

Тем не менее, отметим, что в более современных системах, использующих systemd вместо System V init (от которого исходит концепция уровней запуска), подход к уровням запуска немного другой. Здесь они называются целями (targets). Чтобы проверить текущую цель systemd, используйте команду systemctl.

$ systemctl get-default


## 31. Что такое SSH port forwarding? **Что такое проброс портов ssh?**


Это жаргонизм, который означает создание посредством ssh (поверх ssh соединения) криптографически защищенного тоннеля, когда на вашей машине открывается локально слушающий порт, куда может быть направлен трафик ( и получен ответ), и который будет доставлен до удаленной машины или сети и направлен на указанный порт ( возможно в комбинации с удаленным ip адресом)

Проброс портов в SSH - это метод, с помощью которого можно перенаправлять трафик через зашифрованное SSH соединение. Этот процесс углубляет слой безопасности, за счет использования беспрепятственного трафика по SSH каналу.

Есть два типа проброса портов:

Локальный проброс портов (Local Port Forwarding): это позволяет перенаправить трафик на любой порт на вашем локальном компьютере на любой порт на удаленном сервере через центральный сервер.
Есть два типа локального проброса портов:

a) Dynamic: который устанавливает вашу машину как SOCKS прокси сервер и позволяет передвигать трафик по произвольной цепочке SSH туннелей. Пример:

$ ssh -D 8080 -C -q -N user@yourserver.com

b) Static: передвигающий трафик через сервер к конечной точке. Пример:

$ ssh -L 9000:imgur.com:80 user@yourserver.com

Удаленный проброс портов (Remote Port Forwarding): Это позволяет перенаправить трафик на любой порт на удаленном сервере на любой порт на вашем локальном компьютере. Пример:

$ ssh -R 9000:localhost:3000 user@yourserver.com

Все эти команды создают безопасное соединение с SSH-сервером и открывают соединение на соответствующих портах.

## 32. **В чем разница между локальным и удаленным пробросом портов?**


В такой формулировке к сожалению вопрос не очень понятный, я для себя воспринимаю его так:

- мы можем поверх ssh соединения к машине А, пробросить локальный порт со своей машины на некоторый локальный порт машины А. Например у нас есть веб сервер на котором так же установлена СУБД MySQL. Она сконфигурирована так, чтобы принимать соединения только с локальной машины ( в целях безопасности), но мы хотим подключиться к ней удаленно неким клиентским ПО ( стандартной утилитой mysql или графической оболочкой типа MySQL Workbrench). Для этого мы устанавливаем ssh соединения и поверх него настраиваем тоннель, соединяющий наш локальный порт xxx с портом localhost:3360 на удаленном сервере
- Удаленный проброс портов, когда у нас есть возможность соедениться по ssh с машиной в удаленной сети, но по факту нам нужно попасть на другую машину в той же сети, куда прямого доступа нет. Тогда мы можем “пробросить” это соединение через машину, которая нам доступна.


Разница между локальным и удаленным пробросом портов в SSH заключается в направлении перенаправления соединения и типу использования:

Локальный проброс портов (Local Port Forwarding): Этот метод применяется, когда вы хотите обеспечить доступ к удаленному ресурсу из вашей локальной машины через SSH-сервер. Это то, что обычно происходит, когда вы запускаете SSH с опцией -L. Например, если у вас есть веб-сайт, который вы можете просмотреть только с вашего сервера и хотите просмотреть его на своем локальном компьютере, вы можете использовать локальный проброс портов.


$ ssh -L 8080:localhost:80 username@SSH_server

Теперь вы можете просмотреть веб-сайт, открыв в браузере `localhost:8080`.
Удаленный проброс портов (Remote Port Forwarding): Напротив, это используется, когда вы хотите обеспечить доступ к локальному ресурсу из удаленной машины через SSH-сервер. Это то, что обычно происходит, когда вы запускаете SSH с опцией -R. Например, если у вас есть веб-сервер на своем локальном компьютере, и вы хотите, чтобы люди могли получить доступ к нему через ваш SSH-сервер, вы можете использовать удаленный проброс портов.

$ ssh -R 8080:localhost:80 username@SSH_server

Теперь любой, кто подключается к `SSH_server` на порту 8080, будет подключаться к вашему локальному веб-серверу на порту 80.



## 33. Какие шаги надо предпринять, чтоб добавить пользователя в систему не используя утилиты useradd/adduser?

1. Создать соответствующие записи в файлах /etc/passwd, /etc/shadow, /etc/groups
2. Создать домашний каталог с необходимым содержимым
3. Сделать нового пользователя владельцем этого каталога


Добавление пользователя в Linux без использования утилит useradd или adduser включает в себя несколько шагов, включая редактирование нескольких файлов системы. Вот основные шаги:


```bash
# 1. Откройте файл /etc/passwd в редакторе
sudo vi /etc/passwd

# 2. Добавьте новую строку для нового пользователя (в данном примере, новый пользователь 'newuser' с user id 1001 и group id 1000, домашняя директория /home/newuser, и оболочка /bin/bash)
newuser:x:1001:1000:New User:/home/newuser:/bin/bash

# 3. Откройте файл /etc/shadow в редакторе
sudo vi /etc/shadow

# 4. Добавьте новую строку для пароля нового пользователя (в данном примере, пароль не очень защищен)
newuser:*:17647:0:99999:7:::

# 5. Создайте домашнюю директорию для нового пользователя
sudo mkdir /home/newuser

# 6. Измените владельца и группу домашней директории нового пользователя
sudo chown newuser:users /home/newuser

# 7. Установите разрешения для домашней директории нового пользователя
sudo chmod 700 /home/newuser
```

Примечание: Этот метод требует знания структуры файла /etc/passwd и /etc/shadow. Обычно рекомендуется использовать утилиты useradd или adduser, так как они автоматизируют эти шаги и уменьшают риск ошибки.


## 34. Что такое MAJOR и MINOR нумерация спец. файлов?

В системах Unix и Unix-подобных, таких как Linux, каждое устройство представлено в файловой системе через специальные файлы. Эти специальные файлы могут быть двух основных типов:

Файлы символьных устройств (Character Devices)
Файлы блочных устройств (Block Devices)
Оба этих типа устройств различаются способом взаимодействия с ними (блочное устройство обрабатывает данные по блокам, в то время как символьное устройство обрабатывает данные посимвольно).

Сочетание Major и Minor номеров используется для идентификации конкретного устройства в системе:

Major number идентифицирует тип устройства. Например, все TTY устройства будут иметь один и тот же Major номер. Номер указывает на драйвер, который используется для обращения к устройству.

Minor number идентифицирует конкретное устройство, если таких устройств больше одного. Например, если у вас установлено несколько дисков, каждый из них будет иметь свой собственный Minor номер, в то время как Major номер будет один и тот же, указывающий на драйвер диска.

Вместе MAJOR:MINOR номера образуют уникальный идентификатор для каждого устройства в системе.

Пример записи в /dev:

$ crw------- 1 root root 226, 0 Mar 28 18:54 /dev/ttyS0

В этой записи 226 - это Major номер, а 0 - это Minor номер. Это соответствует TTY устройству.

## 35. **Опишите команду mknod и для чего бы вы ее применили?**


Команда используется для создания специальных файлов-устройств — символьных, блочных и именованных каналов типа fifo. Первые два типа сейчас создавать нет смысла — системы типа udev сделают это за вас при подключении устройства, а вот создать именованный fifo канал для связи двух программ можно — первая в канал пишет, вторая из него читает.



Команда mknod в Unix-тайп системах используется для создания специальных или блочных файлов. Эти специальные файлы служат для обращения к устройствам и включают в себя два номера: Major и Minor номер.

Синтаксис команды mknod выглядит следующим образом:

$ mknod [опции] имя тип [мажорный_номер минорный_номер]

Типы файлов, которые можно создать с помощью команды mknod, включают:

b: блочное устройство
c: символьное устройство
p: именованный канал или pipe
Например, чтобы создать новый блочный файл устройства с Major номером 1 и Minor номером 7, вы можете использовать следующую команду:

$ mknod /path/to/newdevice b 1 7

В реальном мире, однако, вы вряд ли будете использовать mknod в повседневной администрации системы. Создание устройств, как правило, автоматизировано через udev в современных системах. Кроме того, создание неправильного устройства или с неправильными параметрами может повредить вашу систему. Это команда преимущественно используется при создании образов файловых систем или внутри chroot окружений, когда вам нужно создать файл устройства вручную.



## 36. **Опишите сценарий, при котором вы получаете сообщение “нет свободного места на файловой системе”, при этом команда “df” показывает что свободное место еще есть?**

Все очень просто — закончились свободные inode на данной файловой системе. То есть свободные блоки на блочном устройстве еще есть, а вот свободные файловые структуры под метаданные файлов в самой файловой системе закончились.

Проверить можно командой:

$ df -i


Есть несколько возможных сценариев, при которых вы можете получить сообщение “нет свободного места на файловой системе”, даже когда команда df показывает, что свободное место еще есть. Одна из наиболее обычных ситуаций - это когда все inode на файловой системе используются.

inode - это структура данных в Unix-типе файловых систем, которая содержит информацию о файлах. Каждый файл использует один inode. Если все inode на файловой системе используются (то есть, для каждого файла был создан inode), вы не сможете создать новые файлы на этой файловой системе, даже если есть свободное место.

Вы можете проверить распределение пространства inode с помощью команды df -ih.

Если это случается, вы в любом случае должны удалить некоторые файлы, чтобы освободить inode, или если это возможно, расширить файловую систему, чтобы создать больше inode.


## 37.Опишите сценарий, когда вы удаляете файл,но 'df' не показывает, что место освободилось.

Опять же, все очень просто — дескриптор удаленного файла остался открыт каким-то приложением, которое тем самым не позволяет освободить место на файловой системе. выход из ситуации — при помощи команды lsof посмотреть список открытых файлов. Удаленные но все еще открытые файлы будут помечены как deleted, но так же вы увидите pid процесса который держит открытый дескриптор. Перезапустите этот процесс ( если это сервис) или просто убейте и вы увидите, что место освободилось!

Сценарий, при котором вы удаляете файл, но команда df не показывает, что место освободилось, обычно связан с тем, что удаленный файл все еще открыт и используется одним или несколькими процессами.

В Unix и Unix-подобных системах, включая Linux, файл не полностью удаляется до тех пор, пока он открыт хотя бы одним процессом. Информация о файле удаляется из каталога, и по этому файлу больше не возможно получить доступ через файловую систему, но сам файл все еще существует на диске пока последний процесс не закроет его.

Чтобы получить список всех процессов, которые используют файл, вы можете использовать команду lsof /path/to/file. Найдите процессы, которые все еще держат файл открытым и завершите их, либо изначально остановите соответствующие службы прежде чем удалять файл.

Этот сценарий довольно общий при работе с файлами журналов и т.п., которые могут все еще использоваться, даже после того как вы попытались их удалить.


## 38. **Опишите, как работает утилита “ps”?**


В Linux  команда ps работает со специальной псевдофайловой системой [proc](https://en.wikipedia.org/wiki/Procfs#Linux). Каталог  /proc/_PID_  содержит большое количество различных файлов, которые предоставляют информацию о процессе с номером _PID_. Эти файлы и каталоги создаются “на лету” ядром операционной системы

Вы сами можете убедиться в этом, используя утилиту strace при запуске команды ps  — вы увидите все системные вызовы и файлы, которые открывает программа.


Утилита ps в Unix и Unix-подобных операционных системах включает в себя "отображение статуса процесса". Она используется для просмотра информации о процессах, которые в настоящее время запущены в операционной системе.

Ниже приведена простая команда ps, которую можно запустить:

ps

Эта команда вернет список процессов, запущенных в текущем рабочем терминале.

PID: идентификатор процесса.
TTY: идентификатор терминала.
TIME: затраченное процессорное время.
CMD: название выполняемой команды.
Часто используется с различными опциями, такими как -e, -f, и т.д. чтобы увидеть больше информации или для отображения процессов вне текущего терминала.

bash

ps -ef
UID: ID пользователя, который запустил процесс.
PID: идентификатор процесса.
PPID: идентификатор родительского процесса.
C: приоритет процессора.
STIME: время, когда процесс был запущен.
TTY: информация о терминале.
TIME: CPU время, использованное для выполнения процесса.
CMD: команда, приводящая к запуску процесса.
Это всего лишь несколько примеров того, что можно делать с ps. Утилита ps - это мощный инструмент для мониторинга и управления процессами в вашей системе, и имеет множество опций и ключей для контроля детализации вывода.

## 39. **Что происходит, когда дочерний процесс умирает, не имея родителя, который бы дождался окончания его работы и чем это плохо?**


Когда процесс завершается, он передает свою статусную информацию родительскому процессу через системный вызов wait(). Если родительский процесс не вызывает wait(), то статус завершенного процесса сохраняется в системе, создавая так называемые "процессы-зомби".

Если дочерний процесс завершается, а родителя уже нет (например, он также завершился), то дочерний процесс становится "сиротой". В Unix и Unix-подобных системах, таких как Linux, "сироты" становятся дочерними процессами процесса с ID 1, обычно init, или в некоторых системах, таких как Ubuntu, systemd. Этот процесс будет периодически вызывать wait(), чтобы очистить завершенные процессы-сироты и предотвратить накопление процессов-зомби в системе.

Несмотря на то, что процессы-зомби не потребляют процессорного времени и большинство ресурсов, они все еще занимают место в таблице процессов ядра, и если эта таблица заполнится, система не сможет создавать новые процессы. Это особенно критично для долго работающих систем, таких как серверы.


## 40. **Кратко объясните каждое из состояний процесса?**


В операционных системах Linux процесс может находиться в одном из следующих состояний:

Running: Процесс либо выполняется, либо ожидает выполнения в очереди процессора.

Interruptible sleep: Процесс заблокирован (означает, что процесс ожидает какого-то ресурса), и он может быть разбужен и прерван прерыванием.

Uninterruptible sleep: Процесс заблокирован и для него не доступны прерывания. Обычно это означает, что процесс ожидает некоторое основное I/O действие.

Stopped: Процесс был остановлен, обычно пользовательским вводом, например, SIGSTOP или SIGTSTP. Процесс может быть продолжен командой SIGCONT.

Zombie: Процесс завершился, но его родительский процесс еще не забрал информацию о завершении. В этом состоянии процесс уже не выполняется, но все еще присутствует в таблице процессов.

Dead: Процесс полностью завершился и был удален из таблицы процессов. Он больше не существует. Это состояние было введено в вариантах ядра Linux 2.6 и в дальнейшем.

Все эти состояния помогают в управлении процессами и ресурсами системы.

## 41. **Как узнать какой процесс слушает указанный порт?**

Вы можете использовать утилиту lsof с параметром -i:port. Здесь port - это номер порта, который вы хотите проверить.

Вот пример:

lsof -i:80

Эта команда выведет список всех процессов, слушающих порт 80.

Если lsof не доступен, вы также можете использовать утилиту netstat с флагами -tuln:

netstat -tuln | grep :80

Эта команда вернет все процессы, прослушивающие порт 80. grep здесь используется для фильтрации результата и вывода только тех строк, которые содержат ':80'.

>Есть старый и новый способ.

Старый способ- использовать команду netstat — например мы хотим узнать кто слушает 53/tcp порт:

sudo netstat -antpl | grep 53  | grep -i listen

Новый способ — утилита ss. Посмотрим для того же порта:

> sudo ss -antpl | grep 53   

## 42. Что такое зомби-процесс и какова его причина возникновения?

Зомби-процесс - это процесс в Unix и Unix-подобных системах, который завершился, но по каким-то причинам информация о его завершении еще не передана родительскому процессу. Эта информация остается в системе в виде процесса-зомби.

Рассмотрим, когда и как происходит создание зомби-процессов:

- Когда процесс (давайте назовем его Ребенок) завершается, операционная система хранит информацию о его завершении для родительского процесса. В частности, это сделано для того, чтобы родительский процесс знал статус завершения Ребенка (например, завершился ли он успешно, какой выходной код он вернул и т.д.).

- Информация о завершении дочернего процесса передается родительскому процессу через системный вызов wait(). Родительский процесс вызывает wait() для того, чтобы заполучить эту информацию и сигнал о завершению.

- Если родительский процесс не вызывает wait(), информация о завершении не удаляется и процесс остается в состоянии зомби.

- Зомби-процесс не потребляет ресурсы (кроме записи в таблице процессов), но может стать проблемой, если процессов-зомби становится слишком много и они заполняют всю таблицу процессов.

В большинстве случаев зомби-процессы являются результатом ошибки программирования: неправильно написанный парентальский код не вызывает wait(), и процессы-зомби остаются неконтролируемыми.


## 43. Вы запускаете bash скрипт и хотите видеть его вывод на экране и одновременно сохранить этот вывод в файл. Как это сделать?

Для того чтобы вывести информацию на экран и одновременно сохранить ее в файл, вы можете использовать команду tee. Здесь как это может выглядеть:

$ bash script.sh | tee output.txt

В данной команде script.sh - это ваш скрипт, а output.txt - имя файла, в который будет сохранен вывод. Если файл с таким именем уже существует, он будет перезаписан. Если вы хотите добавить вывод в конец существующего файла, вместо перезаписи, используйте tee -a:

$ bash script.sh | tee -a output.txt

В обоих случаях вывод скрипта script.sh будет отображаться в консоли и сохраняться в файл output.txt.


## 44. Объясните, что делает echo "1" > /proc/sys/net/ipv4/ip_forward.

Эта команда используется для включения функции IP forwarding (перенаправления IP) в Linux системе.

/proc/sys/net/ipv4/ip_forward - это параметр ядра, который определяет, должен ли компьютер перенаправлять пакеты, которые он получает, но которые предназначены для другого устройства.

"1" означает включение этой функции, "0" - выключение.

При вводе echo "1" > /proc/sys/net/ipv4/ip_forward, вы записываете "1" в файл ip_forward, что очень прямолинейно включает IP forwarding.

Это действие обычно применяется на маршрутизаторах и серверах, которые должны передавать трафик между двумя и более сетями.


## 45. Кратко объясните, какие шаги надо предпринять, чтоб создать и установить сертификат для сайта [https://foo.example.com](https://foo.example.com).

Сгенерируйте новый приватный ключ:

$ openssl genrsa -out foo.example.com.key 2048

 Создайте запрос на подпись сертификата (CSR):
 
$openssl req -new -key foo.example.com.key -out foo.example.com.csr

Отправьте CSR файл в центр сертификации (CA), например, Let's Encrypt или DigiCert. Они проверят ваш контроль над доменом и выдадут вам сертификат.

Когда вы получите сертификат, сохраните его в файл, назовем его "foo.example.com.crt".

Установите ключ и сертификат на вашем web-сервере. Настройка зависит от того, какой web-сервер вы используете. Если это Nginx, ваши настройки могут выглядеть следующим образом:

ssl_certificate /etc/ssl/foo.example.com.crt;
   ssl_certificate_key /etc/ssl/foo.example.com.key;

Перезапустите ваш web-сервер, чтобы применить изменения. В случае Nginx команда может выглядеть так:

$service nginx restart

Теперь ваш сайт должен использовать HTTPS соединение.


## 46. Можно ли создать несколько HTTPS виртуальных хостов, используя один IP?

Да, можно создать несколько HTTPS виртуальных хостов, используя один IP, благодаря технологии Server Name Indication (SNI). SNI позволяет веб-серверу обслуживать разные сертификаты SSL для разных сайтов, даже если они имеют один и тот же IP-адрес.

В примере Nginx:

```
server {
    listen 443 ssl;
    server_name www.example1.com;
    ssl_certificate /etc/nginx/ssl/example1.com.crt;
    ssl_certificate_key /etc/nginx/ssl/example1.com.key;
    ...
}

server {
    listen 443 ssl;
    server_name www.example2.com;
    ssl_certificate /etc/nginx/ssl/example2.com.crt;
    ssl_certificate_key /etc/nginx/ssl/example2.com.key;
    ...
}
```

Конфигурация выше показывает, как можно настроить два HTTPS виртуальных хоста (www.example1.com и www.example2.com) на одном IP-адресе в Nginx, используя разные SSL сертификаты.


## 47. Что такое wildcard сертификат?

Wildcard сертификат - это SSL сертификат, который можно использовать с любым субдоменом одного и того же домена. Он начинается со звездочки (например, *.example.com), которая представляет собой метасимвол, обозначающий "любое количество любых символов". Это означает, что один wildcard сертификат можно использовать для безопасности множества поддоменов без необходимости получение отдельного сертификата для каждого из них.

Пример использования в Nginx:

```
server {
    listen 443 ssl;
    server_name *.example.com;
    ssl_certificate /etc/nginx/ssl/wildcard.example.com.crt;
    ssl_certificate_key /etc/nginx/ssl/wildcard.example.com.key;
    ...
}
```

В этом примере, wildcard сертификат (wildcard.example.com.crt) был создан для *.example.com и может обслуживать субдомены типа sub1.example.com, sub2.example.com, и т.д., без необходимости создавать отдельные блоки сервера для каждого субдомена.

## 48. Какие типы файловых систем в Linux вам известны?

В Linux существует множество различных файловых систем. Ниже приведены некоторые из наиболее распространенных:

ext2/ext3/ext4 - Это заметно самые распространенные файловые системы, используемые в Linux. Более старые версии, такие как ext2, уже не так часто используются, но ядра Linux до сих пор поддерживают их. ext3 добавил в файловую систему журналирование, а ext4 привнес ряд улучшений в отношении производительности и стабильности.

FAT16/FAT32 - Это файловые системы DOS/Windows, которые совместимы с большинством операционных систем и устройств.

NTFS - Это основная файловая система, используемая в более новых версиях Windows. Linux поддерживает чтение и запись в NTFS через драйвер ntfs-3g.

XFS - Файловая система, созданная SGI, которая хорошо работает с большими файлами и была рекомендована для использования с файловыми системами большого размера.

Btrfs - Современная файловая система, разработанная Oracle, которая предлагает улучшенное управление хранилищем, включая снимки и управление томами.

ZFS - Это еще одна современная файловая система с большим набором функций, включая управление томами и снимками, интегрированную проверку целостности и репликацию.

tmpfs - Это файловая система, хранящая все файлы в памяти.

JFS - Разработанная IBM файловая система с функцией журналирования.

ReiserFS/Reiser4 - Файловые системы с высокой производительностью для работы с большим количеством маленьких файлов.

Это только некоторые из многих доступных файловых систем. Конкретная файловая система, которую вы выберете, зависит от ваших требований к системе хранения.

Выбор файловой системы для высоконагруженного сервера зависит от специфических требований вашего случая использования. Вот несколько популярных опций:

ext4: Это самая распространенная файловая система в Linux. Она предлагает хороший баланс между производительностью и надежностью и поддерживает большие тома и файлы.

XFS: Эта файловая система хорошо подходит для серверов с большими объемами данных. XFS специально оптимизирована для таких операций, как параллельная обработка и журналирование, что делает ее хорошим выбором для высоконагруженных серверов.

Btrfs: Btrfs предлагает функции, такие как снимки и управление томами, которые могут быть полезны на серверах с большим объемом данных. Однако эта FS все еще находится в активной разработке и может быть не столь надежной как ext4 или XFS.

ZFS: Если у вас есть требования к управлению томами, широким функционалом, аппаратным уровнем контроля целостности данных, то ZFS может быть высокоэффективным выбором, но она требует больше ресурсов, в частности, оперативной памяти.

В итоге, выбор файловой системы зависит от конкретных требований к производительности, доступности и прочности данных.


Выбор между Btrfs и ZFS в большей степени зависит от ваших конкретных потребностей. Каждая из этих файловых систем имеет свои сильные и слабые стороны.

Btrfs:

Btrfs поддерживает как много томов, так и подтомы в рамках единой файловой системы, что облегчает управление.
Btrfs уменьшает фрагментацию файлов за счет использования копирования при записи (COW).
Btrfs более нативно интегрирована с Linux, так как она входит в стандартное ядро Linux.
ZFS:

ZFS имеет встроенную возможность контроля целостности. ZFS автоматически исправляет ошибки при чтении/записи на диск.
ZFS предлагает непосредственную поддержку RAID, включая RAID-Z для защиты от отказа диска.
ZFS потребляет больше системных ресурсов, особенно оперативной памяти.
Обе системы предлагают хорошие возможности для управления томами и снимками данных. Если вам требуется большая надежность и вы готовы потратить дополнительные ресурсы на поддержание ZFS, ZFS может быть хорошим выбором. Если вам нужна более простая интеграция и управление с Linux, Btrfs может быть предпочтительнее.

## 49. В чем разница между процессом и потоком? И родительским и потомком процессами после системного вызова fork?

Процесс - это экземпляр программы в работе, включающий исходный код программы, ее текущее состояние и все ресурсы, которыми она пользуется. Процессам выделено пространство в памяти, и они не делят это пространство с другими процессами. В каждом процессе может быть один или более потоков.

Поток, с другой стороны, - это наименьшая единица обработки, которую можно запланировать и выполнить в операционной системе. Поток - это "подпроцесс" в рамках процесса. Все потоки в рамках одного процесса делят оперативную память и ресурсы процесса.

Системный вызов fork() в Unix/Linux создает новый процесс путем клонирования текущего процесса. Новый процесс - это "дочерний" процесс, а исходный процесс становится "родительским".

Родительский процесс - это процесс, который создает один или несколько новых процессов.

Дочерний процесс, или подпроцесс, создается из родительского процесса. После вызова fork(), оба процесса (родительский и дочерний) выполняются параллельно. Любые изменения, произведенные в дочернем процессе, не затрагивают родительский процесс, и наоборот, потому что у каждого процесса есть его собственная область памяти.


## 50. В чем разница между exec и fork?

fork() и exec() - это системные вызовы в Unix/Linux, и они имеют различные функции в процессе создания и исполнения процессов.

fork() создает новый процесс, клонируя существующий процесс. Новый процесс называется дочерним процессом, а исходный процесс - родительским. Эти процессы выполняются независимо друг от друга, но дочерний процесс начинает свое исполнение с того места, где был вызван fork() в родительском процессе.

```c
#include <sys/types.h>
#include <unistd.h>

pid_t pid = fork();
```

exec() используется в дочернем процессе для замены текущего исполняющегося кода на код другой программы. Этот новый код начинает исполняться с функции main(). В нормальных условиях выполнение программы не возвращается к процессу, который вызвал exec().

```c
#include <unistd.h>

execl("/path/to/program", "program", (char *)0);
```

Итак, обычно комбинация этих двух системных вызовов используется для создания и запуска новых процессов в Unix/Linux системах.

## 51. Для чего используется `nohup`?


Команда nohup в Unix/Linux используется для запуска команд или процессов в фоновом режиме. Он предотвращает процессы от остановки из-за завершения сеанса пользователя или отключения сетевого соединения. При этом stdout и stderr переадресуются в файл nohup.out, если иное не указано.

Вот пример использования nohup:

```
nohup command-to-run &
```

Здесь command-to-run это команда, которую вы хотите выполнить, а & отсылает процесс в фоновый режим.

Таким образом, использование nohup полезно, если вы хотите, чтобы ваш процесс продолжал выполнение даже после завершения вашего сеанса или отключения.

## 52. - В чем разница между этими двумя командами?
- `myvar=hello`
- `export myvar=hello`


myvar=hello создаёт переменную среды только для текущего shell. Если запустить другой shell-процесс (например, открыв другое окно терминала или запустив программу из текущего shell), эта переменная не будет доступна в этом новом процессе.

export myvar=hello делает то же, что и myvar=hello, но кроме того, делает переменную доступной для всех child-процессов текущего shell. Это означает, что если вы запустите другой shell-процесс от текущего shell, переменная будет доступна и в этом новом процессе.

В общем, export используется, когда вы хотите сделать переменную доступной для других процессов.


## 54.  Как много NTP севреров настроено в вашем локальном ntp.conf?


NTP (Network Time Protocol) сервер - это сервер, который использует протокол NTP, чтобы синхронизировать время на компьютерах и других устройствах в сети. Это важно для многих сетевых приложений и служб, которые полагаются на точное время для своей работы.

NTP серверы работают, синхронизируя свои часы с более точными источниками времени, такими как атомные часы, GPS или другие NTP серверы высокого уровня, а затем предоставляют эту информацию о времени устройствам, которые к ним подключаются.

Ваши компьютеры и другие устройства могут быть настроены на автоматическую синхронизацию времени с NTP сервером, обеспечивая точность вашей системы.

Количество NTP серверов, настроенных для использования на ваших серверах, может варьироваться в зависимости от ваших потребностей в точности и отказоустойчивости. Однако общепринятой практикой является конфигурация минимум трёх NTP серверов.

1-2 NTP сервера могут обеспечить базовую синхронизацию времени, но если один из них станет недоступным или его время перестанет быть точным, ваша система может получить неправильное время.

Настройка трёх серверов позволяет вашей системе сравнивать время с между тремя источниками и выбирать самый точный. Это также предоставляет более высокий уровень отказоустойчивости, поскольку даже если один сервер станет недоступным, у вас все еще будут два других для синхронизации.

Для критически важных систем или систем с высокими требованиями к точности времени, могут быть настроены больше серверов.



## 55. Что означает колонка 'reach' в выводе `ntpq-p`?

В выводе ntpq -p, колонка reach показывает октальное значение (в формате основания 8) и связано со статусом доступности NTP сервера.

Это 8-битное поле, где каждый бит представляет одно из последних восьми попыток связаться с сервером. Если попытка связи была успешной, соответствующий бит устанавливается в 1; если попытка была неудачной, бит устанавливается в 0.

Обратите внимание, что поскольку это октальное значение, его можно преобразовать в двоичный формат для визуализации отдельных битов.

Значение 377 октальной системы, например, означает, что все последние 8 попыток связи с сервером были успешными, поскольку 377 октальных будет 11111111 в двоичной системе.

## 56. Вам необходимо обновить ядро на 100-1000 серверах, как вы будете это делать?


В ситуации с множеством серверов, обновление ядра лучше всего выполнять автоматизированным способом. Для этого организации часто используют инструменты управления конфигурацией, такие как Ansible, Puppet или Chef.

В случае использования Ansible (что популярно из-за его простоты и универсальности), вы могли бы написать плейбук, который обновляет ядро на каждом сервере, после чего перезагружает сервер.

Вот пример Ansible плейбука:

```yml
---
- hosts: all_servers
  tasks:
  - name: Update all packages
    yum:
      name: '*'
      state: latest
    become: yes

  - name: Reboot server
    reboot:
    become: yes
...
```

В этом примере hosts: all_servers указывает, что действия должны быть выполнены на всех серверах в группе all_servers. Замените это на имя своей группы серверов.

Помимо этого, важно провести тест обновления на нескольких серверах перед запуском процесса обновления на всех серверах, чтобы обеспечить, что обновление ядра не вызывает проблем.

Также может быть полезно использование систем почтовых уведомлений или уведомлений в операционные системы для сбора информации о ходе выполнения процесса обновления.

Прежде чем начинать такой важный процесс, убедитесь, что у вас есть актуальное резервное копирование и восстановление.


## 57.Как можно получить Host, Channel, IS, LUN для SCSI диска?


SCSI (Small Computer System Interface) - это стандарт для параллельной и последовательной передачи данных между компьютерами и периферийными устройствами.

Устройства SCSI включают широкий спектр оборудования, такого как жесткие диски, сканеры, CD-ROM, DVD, принтеры и многие другие. SCSI известен своей универсальностью и производительностью, и во многих случаях он может поддерживать до 7 или 15 устройств на одном контроллере SCSI.

Однако сегодня интерфейс SCSI в основном используется в серверных и сетевых решениях хранения данных для подключения высокопроизводительных жестких дисков и накопителей на ленте.

Устройство SCSI присваивают номер (ID) от 0 до 15 (или от 0 до 7 для старых устройств). Каждое устройство на шине должно иметь уникальный ID. Контроллер SCSI, также известный как хост-адаптер SCSI, обычно присваивает ID 7, поскольку это приоритетный ID, и он всегда примется во внимание в первую очередь.

Для получения такой информации в Linux, вы можете использовать lsscsi. Установить его можно с помощью менеджера пакетов вашего дистрибутива. Если у у вас его нет, установите с помощью команды:

sudo apt-get install lsscsi
lsscsi -g



## 58. Как можно ограничить использование памяти для процесса?


Вы можете использовать "cgroups" (control groups) в Linux для ограничения использования памяти для процесса. Ниже приведен пример, который устанавливает ограничение памяти в 500M for a процесса с ID 12345:

```bash
# Создать cgroup с ограничением памяти в 500M
mkdir /sys/fs/cgroup/memory/limit
echo 500M > /sys/fs/cgroup/memory/limit/memory.limit_in_bytes

# Добавить процесс в cgroup
echo 12345 > /sys/fs/cgroup/memory/limit/cgroup.procs
```

Не забудьте заменить "12345" на реальный ID процесса, который вы хотите ограничить. Вы можете использовать команду ps или top для поиска ID процесса.

Помните, что вы должны быть суперпользователем (root), чтобы использовать этот метод, и он работает на ядрах Linux, которые поддерживают cgroups.

## 59. Что такое быстрый поиск и замена в bash (^x^y)?

В Bash, ^x^y^ это быстрая команда для поиска и замены. Она заменяет первое вхождение x в последней выполненной команде на y и затем выполняет новую составленную команду.

Например, если вы ввели следующую команду:

```
echo helo world
```

Вы понимаете, что допустили ошибку в слове "hello". Вместо того, чтобы полностью повторно вводить команду, вы можете просто выполнить:

```
^helo^hello^
```

Bash заменит "helo" на "hello" в предыдущей команде, и выполнит исправленную команду, то есть echo hello world.

Этот разделитель (caret - ^) синтаксис подходит только для простых опечаток и быстрых замен. Для более сложных сценариев рекомендуется использовать полнофункциональную иcторию bash или другие инструменты, такие как sed или awk.

## 60. Какие вы знаете альтернативные оболочки? Какую вы используете?

Существуют различные оболочки Unix, которые предоставляют различные возможности и синтаксис. Некоторыми из наиболее популярных оболочек являются:

Bash (Bourne Again Shell): Это самая распространенная оболочка в Linux. Она обладает многими возможностями и включает в себя функции программирования.

sh (Bourne Shell): Это одна из старейших оболочек Unix. Большинство других оболочек в той или иной степени основаны на sh.

csh (C Shell): Оболочка с синтаксисом, похожим на язык программирования С.

tcsh: Это улучшенная версия csh с дополнительными функциями, такими как автозавершение и история команд.

ksh (Korn Shell): Оболочка, разработанная Дэвидом Корном в AT&T Labs. Она сочетает в себе лучшие характеристики csh и sh.

zsh (Z Shell): Это одна из наиболее мощных оболочек, которая включает усовершенствованные функции автозавершения и настраиваемую функциональность.

fish (Friendly Interactive Shell): Оболочка с упором на пользователя, которая не является полностью совместимой со скриптами Bash или sh, но предлагает многие удобные функции и улучшения пользовательского интерфейса.

Ваш выбор оболочки зависит от ваших критериев, таких как совместимость, удобство написания и чтения скриптов, наличие определенных функций и личные предпочтения. На сегодняшний день, многие разработчики предпочитают использовать оболочку zsh, особенно с Oh-My-Zsh, что делает работу в оболочке намного приятнее и продуктивнее.

## 61. Что такое tarpipe (или, как вы будете копировать все, включая жесткие ссылки и специальные файлы, с одного сервера на другой)?

Tarpipe - это термин, обычно используемый для описания процесса использования команды tar в качестве "трубы" для копирования данных между серверами. Tar собирает все файлы в один архив и на лету передает его через стандартный вывод, который затем может быть перенаправлен на удаленный сервер через SSH.

Если вы хотите копировать все, включая жесткие ссылки и специальные файлы, с одного сервера на другой, которые также сохраняют все права на файлы и символические ссылки, вы можете использовать следующую команду:

```bash
tar -cf - /path/of/data/to/copy | ssh user@remote "cd /where/to/unpack/; tar -xvf -"
```

Объяснение:

tar -cf - /path/of/data/to/copy - создает архив всех файлов в указанном каталоге и подкаталогах и отправляет его на стандартный вывод.
| - пайп (или "труба"), перенаправляет стандартный вывод из одной команды на стандартный ввод следующей.
ssh user@remote - запускает SSH-сеанс на удаленном сервере.
"cd /where/to/unpack/; tar -xvf -" - переходит в целевой каталог на удаленном сервере и извлекает данные из архива, поступающего по стандартному вводу.
Обратите внимание, что разрешения и владение файлами будут сохранены при использовании этого метода.

## 62. Как можно проверить, что пакет httpd уже был установлен?


Вы можете проверить, был ли установлен пакет httpd, используя менеджер пакетов вашего дистрибутива Linux. Для систем на основе apt (например, Ubuntu или Debian), вы можете выполнить следующую команду:

```
dpkg -s httpd
```

Для систем на основе yum или dnf (например, CentOS или Fedora), вы можете выполнить следующую команду:

```
yum list installed httpd
# или
dnf list installed httpd
```

Для систем на основе zypper (OpenSUSE):

```
zypper info httpd
```

```
pacman -Q httpd
```

Если пакет был установлен, команда вернет информацию об этом пакете. Если пакет не был установлен, вы получите сообщение об ошибке или ничего не будет выведено.

## 63. Как посмотреть содержимое установочного пакета?

Для просмотра содержимого установочного пакета без его установки, вы можете использовать менеджер пакетов вашей операционной системы. В зависимости от вашей системы и типа пакета, команды могут быть разными:

Debian/Ubuntu (.deb файлы)

$ dpkg -c /path/to/package.deb

## 64. Как вы определите какой пакет лучше: openssh-server-5.3p1-118.1.el6_8.x86_64 или openssh-server-6.6p1-1.el6.x86_64?

Версий пакетов openssh-server-5.3p1-118.1.el6_8.x86_64 и openssh-server-6.6p1-1.el6.x86_64, версия openssh-server-6.6p1-1.el6.x86_64 скорее всего будет предпочтительнее, так как она больше по номеру, что обычно означает новые исправления ошибок, улучшения безопасности и/или добавление функциональности.

Однако этот выбор может зависеть от конкретного контекста. Для некоторых сценариев использования более старая версия может быть предпочтительной из-за совместимости, стабильности или задокументированных тестов.

Также, стоит учитывать, что номер у версии openssh-server-5.3p1-118.1.el6_8.x86_64 может восприниматься как "больший" из-за наличия большего числа после дефиса, но эта часть обычно относится к номеру сборки или релиза пакета для конкретной системы, и не отражает сам версионный тракт от разработчиков openssh, где 6.6p1 будет новее чем 5.3p1.

## 65. Что такое туннель и как вы можете обойти http прокси?

Туннеллирование используется для передачи данных, которые обычно блокируются в определенной сети.

В контексте сетей и прокси, туннель обозначает путь между двумя точками в сети, где все передаваемые данные зашифрованы или упакованы внутри другого протокола или типа данных. Это делает их невидимыми для просмотра или их невозможно идентифицировать как заблокированные данные.

Вы можете обойти HTTP прокси с использованием SSH туннелирования, или создания TCP туннеля через прокси-сервер.

Для SSH туннелирования вам нужно будет иметь SSH доступ к удаленному серверу. Затем вы создаете SOCKS прокси, который маршрутизирует весь трафик через SSH туннель. Вот как вы можете сделать это:

```
ssh -D 8080 username@remoteserver.com

```

Здесь 8080 - это порт, на котором будет запущен SOCKS прокси на вашей локальной системе. username - ваше имя пользователя на remoteserver.com.

Теперь вы можете настроить ваш браузер или другую программу использовать этот SOCKS прокси для обхода HTTP прокси.

## 66. В чем разница между IDS и IPS?

IDS (Intrusion Detection System) и IPS (Intrusion Prevention System) оба представляют собой системы защиты сети, но они играют разные роли.

IDS - система обнаружения вторжений, она мониторит сетевой трафик на наличие подозрительной активности и уведомляет об этом. Однако IDS не предпринимает действий для блокирования или предотвращения замеченной активности.

IPS - система предотвращения вторжений, которая, помимо мониторинга сетевой активности, также способна предпринимать действия для блокирования или предотвращения замеченной подозрительной активности или атак.

Таким образом, основное различие между IDS и IPS заключается в том, что IDS пассивно мониторит сетевой трафик и уведомляет об подозрительной активности, в то время как IPS активно вмешивается и блокирует потенциально вредную активность.

## 67. Какие горячие клавиши вы используете регулярно?

В терминале Linux также существует ряд горячих клавиш, которые облегчают работу. Некоторые из них:

Ctrl+C: Прерывает текущую команду
Ctrl+D: Закрывает оболочку
Ctrl+Z: Помещает текущую команду (или процесс) в фон
Ctrl+A: Перемещение к началу строки
Ctrl+E: Перемещение к концу строки
Ctrl+K: Удалить все после местоположения курсора до конца строки
Ctrl+U: Удалить все от местоположения курсора до начала строки
Ctrl+R: Искать в истории команд
Ctrl+L: Очистить экран
Ctrl+P: Предыдущая команда в истории команд
Ctrl+N: Следующая команда в истории команд
Up Arrow: Предыдущая команда в истории команд
Down Arrow: Следующая команда в истории команд
Alt+F: Перемещение вперёд на одно слово
Alt+B: Перемещение назад на одно слово
Tab: Автозавершение команды или файла.

## 68. Что такое Linux Standard Base?

Linux Standard Base (LSB) — это стандарт, определяющий основные компоненты и поведение систем семейства UNIX-like, в частности Linux. Этот стандарт разрабатывается организацией Linux Foundation и он направлен на обеспечение совместимости между различными дистрибутивами Linux и упрощение написания приложений путем определения стандартного набора интерфейсов и окружения.

LSB определяет стандарты для системных скриптов и их обработки, имен файлов, файловой системы, сетевых адресов и даже графической системы.

Любой дистрибутив Linux может быть сертифицирован как совместимый с LSB, если соответствует этим стандартам. Хотя все дистрибутивы не полностью совместимы с LSB, большинство важных частей системы это делают.

Цель LSB — развитие и стандартизация Linux и UNIX-совместимых систем без ограничения инноваций и конкурентоспособности.


## 69. Что такое атомарная операция?


В операционной системе Linux атомарная операция - это операция, которая выполняется целиком, полностью и неделимо. Она исключает возможность прерывания в середине процесса, что обеспечивает целостность и согласованность системных данных и ресурсов.

Например, операции чтения и записи для типов данных, размер которых не превышает размера естественного для архитектуры процессора (как правило, это 32 или 64 бита), обычно являются атомарными. Это означает, что данные не могут быть вытеснены в середине операции. Если вы читаете или записываете 32-битное значение в 32-битной системе, такая операция будет атомарной - это гарантирует, что вы не получите значения, которое является частично старым и частично новым.

Linux также предоставляет набор системных вызовов и функций, которые являются атомарными, например, fetch_and_add, compare_and_swap (CAS), и другие. Эти функции особенно важны при работе с общими ресурсами в многопоточных приложениях, чтобы исключить возможность состояния гонки и сохранить целостность данных.

## 70. Вы только что настроили http сервер, который не запустился после рестарта. Что вы будете делать?

Первым шагом будет проверка журналов сервера для установки причины сбоя. В случае сервера Apache это может быть команда:

$ sudo tail -n 20 /var/log/apache2/error.log

Не забудьте заменить путь /var/log/apache2/error.log путем до вашего файла журнала, если он разный. Это покажет последние 20 строк журнала ошибок, которые должны содержать информацию о том, что пошло не так.

Если из журнала вы не получили нужной информации, вы можете попробовать проверить конфигурацию сервера (синтаксис) командой:

```
apachectl configtest
```

Это покажет, есть ли ошибки в файлах конфигурации.

Другой возможной проблемой могут быть недостающие или поврежденные файлы, проблемы с правами доступа или проблемы с языком программирования/стандартными библиотеками (если используются скрипты на стороне сервера). Команды, которые могут быть полезны для проверки этих проблем, могут включать ls, cat, less, file, ldd, strace, lsof и т.д.

Наконец, убедитесь, что порт, на котором должен работать ваш сервер, не занят другим процессом, используя команду netstat -tuln.


## 71. Какие ключи содержатся в ~/.ssh/authorized_keys и для чего нужен этот файл?

Файл ~/.ssh/authorized_keys в Unix и Unix-подобных операционных системах, таких как Linux, содержит публичные ключи для аутентификации СSH.

При использовании аутентификации на основе ключей, можно сгенерировать безопасную пару ключей (один приватный и один публичный) на локальной системе, а затем копировать публичный ключ на удалённый сервер.

При подключении к удалённому серверу, он будет проверять этот ключ в файле ~/.ssh/authorized_keys и позволит вам подключиться без введения пароля, если ключи совпадают.

В одном файле ~/.ssh/authorized_keys может быть несколько публичных ключей, каждый из которых соответствует приватному ключу на клиентской машине, отсюда можно управлять доступом множества пользователей или систем к серверу.

Обычно каждый ключ в файле ~/.ssh/authorized_keys начинается с вида алгоритма (например, ssh-rsa), за которым следует сам ключ, а затем комментарий для идентификации ключа.

## 73. Я добавил свой публичный ключ в authorized_keys, но до сих пор получаю запрос пароля. Что может быть не так?

Если вы добавили публичный ключ в ~ / .ssh / authorized_keys на удаленном сервере и все равно по-прежнему получаете запрос пароля, это может быть связано с одной из следующих проблем:

Неправильные разрешения на каталоги / файлы:
Каталог домашнего каталога пользователя (~) на сервере должен быть доступен только для чтения и записи пользователя (запрет чтения / записи / выполнения для других). Правильные разрешения можно установить с помощью chmod 700 ~
Каталог ~/.ssh также должен быть защищен. Установить правильные разрешения можно с помощью chmod 700 ~/.ssh
Файл ~/.ssh/authorized_keys должен быть доступен только для чтения и записи пользователем. Установить правильные разрешения можно с помощью chmod 600 ~/.ssh/authorized_keys
Проверьте, правильно ли вы скопировали свой публичный ключ. Он должен быть на одной линии в файле authorized_keys.

Настройки сервера SSH не разрешают аутентификацию на основе ключей. Для этого откройте файл /etc/ssh/sshd_config и убедитесь, что установлены следующие настройки:

```
PubkeyAuthentication yes
```


Если вы внесли изменения в этот файл, вам нужно будет перезагрузить сервер SSH с помощью команды sudo systemctl restart ssh или sudo service ssh restart

Вы можете использовать неправильный приватный ключ на своей локальной машине. Убедитесь, что вы используете правильный ключ с помощью параметра -i в ssh, например: ssh -i ~/.ssh/mykey user@host

Если всё остальное в норме, возможно, стоит проверить системный журнал на сервере (/var/log/auth.log или /var/log/secure, в зависимости от вашего дистрибутива Linux), а также добавить флаг -v к команде ssh для вывода подробного отчета об ошибке.

Это также может облегчить дальнейшую диагностику проблемы.


## 74. Вы когда-нибудь собирали RPM, DEB или solaris пакеты?

Как AI, у меня нет личного опыта, но я знаю, как выполнить эти задачи.

Для сборки RPM-пакетов обычно используется утилита rpmbuild. Вы создаете спецфайл, который описывает, как собрать пакет и какие файлы он включает. Затем вы запускаете rpmbuild -ba your.spec для создания RPM-файлов.

Для сборки DEB-пакетов есть множество инструментов, включая dpkg-buildpackage, debuild и pbuilder, каждый из которых имеет свои собственные преимущества. Основной процесс включает в себя создание каталога, который имитирует структуру файловой системы для пакета, написание скрипта управления пакетами и подготовку файла управления DEB.

Сборка пакетов Solaris обычно осуществляется с помощью утилиты pkgmk. Этот процесс также включает в себя создание прототипа файловой системы и написание файла pkginfo (аналогичный файлу управления Debian), а затем запуск pkgmk для создания пакета.

RPM (RPM Package Manager), DEB (Debian Package), и Solaris packages это форматы бинарных пакетов, которые используются в различных дистрибутивах Linux и Unix для автоматизации процесса установки, обновления, удаления и управления программным обеспечением.

RPM: Используется в системах на основе Red Hat, включая Fedora, CentOS, и RHEL. Этот формат позволяет установку, обновление, проверку, и удаление пакетов, содержащих программное обеспечение.

Deb: Это формат пакетов, используемый в системах на основе Debian, включая Ubuntu и его производных. Deb пакеты упаковываются с DPKG и обычно устанавливаются с помощью APT.

Solaris packages: Используются в операционной системе Solaris от Oracle. Они позволяют управлять программным обеспечением в этой системе.

Эти пакеты используются для того, чтобы:

Упростить процесс установки ПО. Нет необходимости вручную компилировать исходный код.
Управлять зависимостями. Пакет указывает, какие другие пакеты он требует для работы, и система пакетов автоматически устанавливает эти зависимости.
Удобно обновлять или удалять ПО. С помощью одной команды можно обновить или удалить установленное ПО.
Легко распространять ПО. Разработчики могут упаковать свое ПО в эти форматы пакетов и дистрибутивы Linux могут включать их в свои репозитории ПО.


## 75. Что сделает `:(){ :|:& };:` с вашей системой?

Это определение функции в оболочке bash (shell), известное как "fork bomb".

Основная работа этой функции заключается в том, что она бесконечно создает копии самой себя, засоряя таблицу процессов системы. Это, в свою очередь, делает систему неработоспособной, поскольку новые процессы не могут быть запущены пока не будет завершён или убит хотя бы один из уже запущенных процессов.

Вот что происходит:

:() определяет функцию под названием :
{} определяет тело функции. В этом случае тело функции :|:& означает "вызвать функцию :, передать её вывод в ещё один вызов функции :, который затем отправляется в фон (&).
; является разделителем команд, который отделяет определение функции : от её первого вызова.
Последний : запускает функцию и начинает обусловленную ею "fork bomb".
Не запускайте эту команду, если не уверены в последствиях!




Вы можете использовать команду trap в Bash shell scripts для перехвата и обработки сигналов. Например, вы можете перехватить сигнал SIGINT (который отправляется при нажатии Ctrl+C), чтобы выполнить собственную работу по очистке перед завершением скрипта.

Вот базовый пример:

```bash
#!/bin/bash

# Обработчик сигнала
handle_signal() {
    echo "Получен сигнал SIGINT, выполнение операции очистки..."
    # Здесь место для вашей операции очистки
    exit 1
}

# Перехватывать сигнал SIGINT и вызывать функцию handle_signal
trap 'handle_signal' SIGINT

# Бесконечный цикл, чтобы демонстрировать перехват сигналов
while true; do
    echo "Sleeping for 1 second"
    sleep 1
done
```

В этом примере, если вы запустите этот скрипт и нажмете Ctrl+C для его прерывания, он сначала выполнит функцию handle_signal, прежде чем завершится.


## 76. Можно ли перехватить SIGKILL?

Нет, вы не можете перехватить, заблокировать или игнорировать сигнал SIGKILL (сигнал 9). Это сделано специально для того, чтобы администраторы и ядро системы имели надежный способ завершить процесс в случае, если он не реагирует на другие сигналы.

Код вроде этого не будет работать:

```
trap 'echo You can not stop me!' SIGKILL # This will not work
```

Будьте осторожны, используя сигнал SIGKILL, так как это может привести к нежелательным последствиям, таким как потеря данных, если процесс в момент получения сигнала выполняет важные операции, такие как запись данных. Это лучше использовать как последний вариант, когда другие сигналы (например, SIGTERM) не работают.

## 77. Что происходит, когда ядро Linux запускает OOM killer и как он выбирает какой процесс необходимо убить в первую очередь?

OOM Killer (Out Of Memory Killer) в Linux активируется, когда системе не хватает физической и своп памяти. OOM Killer целью имеет наиболее эффективное освобождение памяти, путем убийства тех процессов, которые используют наибольшее количество памяти и/или имеют наименьшую важность для системы.

Процессы оцениваются по так называемому "OOM score", который можно увидеть в файле /proc/[pid]/oom_score. Большее значение "OOM score" означает, что процесс является более вероятной целью для убийства в случае нехватки памяти.

Параметр oom_score_adj позволяет настраивать "OOM score" для конкретных процессов.

Процесс с наибольшим "OOM score" выбирается для уничтожения в первую очередь. Процессы с особыми привилегиями, активные в данный момент пользователи и системные процессы обычно имеют меньшую вероятность быть выбранными.

Однако стоит отметить, что OOM Killer - это крайняя мера, когда системе не хватает памяти. В идеальном случае система должна быть настроена таким образом, чтобы предотвратить нехватку памяти, включая подходящий размер своп-памяти и эффективное управление ресурсами.

## 78. Опишите процесс загрузки Linux с максимально возможным количеством деталей, начиная с момента включения компьютера и заканчивая получением приглашения командной строки.


Вот подробное описание процесса загрузки системы Linux:

Power-On Self-Test (POST): Загрузка начинается с POST, проверки аппаратного обеспечения компьютера, выполняемой BIOS. Во время этой проверки проверяются процессор, память и ввод-вывод.

Bootstrap loader: BIOS ищет загрузочное устройство (например, жесткий диск, флеш-диск, CD-ROM и др.), затем загружает и выполняет первый сектор с этого устройства - Master Boot Record (MBR).

Master Boot Record (MBR): Расположенный в первом секторе загрузочного диска, MBR содержит загрузочный загрузчик и разделенную таблицу.

GRUB (GRand Unified Bootloader): GRUB находится в MBR и обычно первым делом загрузится. Он предлагает возможность выбрать разные ядра Linux или операционные системы для загрузки, если у вас есть несколько установок.

Ядро Linux: GRUB загружает ядро Linux в память и передает ему контроль.

Инициализация ядра: Ядро сначала инициализирует и настраивает системное оборудование, обнаруженное во время загрузки, используя процедуры, определенные в драйверах ядра.

Процесс init: После загрузки ядра и драйверов устройств ядро запускает первый процесс, известный как init. Этот процесс, который имеет идентификатор процесса (PID) 1, затем запускает другие процессы.

Runlevel/Target: init определяет уровень выполнения (для систем init в стиле SysV) или цель (для системы systemd), который включает набор служб, которые должны быть запущены.

Сценарии запуска: Сценарии инициализации, сохраненные в каталоге rc.d, запускаются для запуска различных системных служб, таких как сетевые службы, демоны и контрольные элементы пользовательского интерфейса.

Приглашение командной строки/диспетчер рабочего стола: Наконец, система отображает приглашение командной строки, требуя вход в систему, или загружает графический менеджер входа в систему или рабочий стол.

## 79. Что такое закрытие в chroot?

chroot это системный вызов в Unix-like системах, который изменяет расположение корневого каталога для текущего процесса и его дочерних процессов. Путь, указанный в качестве аргумента chroot, становится новым корневым каталогом. Процессы внутри chroot не могут получить доступ к файлам и ресурсам вне его дерева каталогов.

Закрытие в chroot часто используется для создания изолированной среды для тестирования или отладки программ без риска для основной системы. Это также часто используется при восстановлении системы, устанавливая chroot на другой Linux установку.

Однако, стоит отметить, что chroot не обеспечивает полную изоляцию или защиту, так как процессы с привилегиями root могут сбежать от него. Для более полной изоляции следует рассмотреть использование контейнеров или виртуализации.



## 80. При попытке отмонтировать каталог получаем ошибку занятости, как найти какой PID держит каталог?

Для определения какой процесс блокирует отмонтирование каталога, вы можете использовать команду lsof, которая предоставляет информацию об открытых файлах и тех процессах, которые их открыли.

Пример команды:
sudo lsof /path/to/mount_point

Эта команда выведет список всех процессов, которые в настоящее время используют файлы в указанной директории (или диске). Вы сможете увидеть PID (идентификатор процесса) каждого из этих процессов, что поможет вам идентифицировать, какой конкретно процесс препятствует отмонтированию каталога.

## 81. Что такое LD_PRELOAD и когда он используется?

LD_PRELOAD это специальная переменная окружения в Unix-like системах, которую можно использовать для загрузки пользовательских библиотек перед всеми остальными. Это позволяет пользователю переопределить любую функцию библиотеки, на которую ссылаются выполняемые файлы. Следовательно, вы можете изменить поведение функций библиотеки для заданного запускаемого бинарного файла.
Без использования LD_PRELOAD, наша программа была бы не определена.

LD_PRELOAD обычно использует для отладки, тестирования, исследования работы программ и функций в библиотеке или для устранения багов в библиотеке без необходимости изменения исходного кода.

Нет, пользовательские библиотеки и модули ядра - это не одно и то же.

Пользовательские библиотеки это такие, которые используются приложениями в пространстве пользователя для предоставления определенной функциональности или поведения. Они работают в режиме пользователя, что означает, что у них есть ограниченные возможности взаимодействия с аппаратным обеспечением или ядром системы.

Для компиляции пользовательских библиотек обычно используется компилятор, такой как GCC.

Примеры пользовательских библиотек включают стандартные библиотеки C (например, glibc в UNIX-подобных системах), которые предоставляют базовые функции, такие как printf, malloc и так далее.

С другой стороны, модули ядра это расширения ядра. Они работают в пространстве ядра, и у них есть полный доступ к аппаратному обеспечению и ядру системы.

Модули ядра могут быть загружены и выгружены в работающее ядро на лету, и они обычно используются для добавления поддержки нового оборудования или файловых систем.

Компиляция модулей ядра требует заголовочных файлов ядра и, как правило, выполняется с помощью команды make.

Одним из примеров модуля ядра может быть драйвер устройства, который позволяет ядру взаимодействовать с конкретным компонентом аппаратного обеспечения.


## 82.Вы запустили бинарник в linux и ничего не произошло. Как вы будете искать проблему?


```
# Используйте ldd для проверки на наличие отсутствующих библиотек:
ldd your-binary-file

# Попробуйте запустить ваш файл с strace чтобы увидеть системные вызовы:
strace ./your-binary-file

# Проверьте статус завершения вашего файла:
./your-binary-file
echo $?

# Используйте команду file для проверки типа файла:
file your-binary-file

# Включите подробный вывод с помощью установки переменной окружения:
export LD_DEBUG=files,libs
./your-binary-file

# Используйте gdb для отладки вашего бинарного файла:
gdb your-binary-file
run
```


## 83. Что такое cgroups? Можете ли вы указать сценарий, когда это может быть использовано?


Cgroups (Control Groups) — это механизм ядра Linux, который используется для ограничения и изолирования ресурсов процессов (таких как использование процессора, памяти, сетевого трафика и т.д.). Он используется для управления ресурсами на уровне системы и позволяет управляющему ПО контролировать, упорядочивать, отслеживать, учёт и гарантировать изоляцию ресурсов.

Пример использования cgroups:

```
# Создание новой cgroup для ограничения памяти
sudo cgcreate -g memory:/mygroup

# Ограничение использования памяти до 1GB
echo $[ 1 * 1024 * 1024 * 1024 ] > /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes

# Запуск процесса в сгруппе
sudo cgexec -g memory:mygroup /usr/bin/myprogram


```

Пример использования cgroups в реальной жизни: Docker и другие технологии контейнеров используют cgroups для ограничения и изолирования ресурсов каждого контейнера. Таким образом, каждый контейнер может быть рассмотрен как отдельная "мини-машина", с ограниченным доступом к ресурсам основной системы.


## 84. Как можно удалить файл, имя которого содержит непечатные символы?

Вы можете удалить такой файл, используя его inode номер. Для этого выполните следующие команды:

```
# Найти inode файлов
ls -il

# Удалить файл по inode
find . -inum [inode-number] -exec rm -i {} \;
```

В первой команде ls -il, i выведет номер inode, а l отобразит вывод в длинном формате. Затем вы используете этот inode номер в команде find для поиска и удаления файла.

Замените [inode-number] на действительный номер inode файла, который вы хотите удалить. Этот подход является безопасным, особенно когда имя файла содержит странные или непечатные символы.

## 85. Как можно увеличить/уменьшить приоритет процесса в Linux?

В системе Linux вы можете изменить приоритет процесса, используя команды nice и renice.

Команда nice позволяет установить приоритет для новых процессов, а команда renice изменяет приоритет уже запущенных процессов.

```
# запуск нового процесса с низким приоритетом
nice -n 10 command

# увеличение приоритета уже запущенного процесса
renice -n -5 -p [process-id]

# уменьшение приоритета уже запущенного процесса
renice -n 15 -p [process-id]
```

В этих командах command заменяется на команду, которую вы хотите выполнить, а [process-id] заменяется на ID процесса, приоритет которого вы хотите изменить.

Значения приоритетов могут варьироваться от -20 (наивысший приоритет) до 19 (наименьший приоритет).

## 86. Что такое run-levels в Linux?

Run levels в Linux - это режимы работы системы, каждый из которых предоставляет различные функции и обеспечивает разный уровень доступа к машине.

Run Level 0: Остановка системы.
Run Level 1: Однопользовательский режим. Часто используется для исправления проблем.
Run Level 2: Многопользовательский режим без сетевого доступа.
Run Level 3: Полный многопользовательский режим. Имеет сетевой доступ, но без графического интерфейса.
Run Level 4: Не используется и зарезервирован для определения пользователем.
Run Level 5: Графический режим, режим по умолчанию в большинстве настольных Linux дистрибутивов.
Run Level 6: Перезагрузка системы.
Команды для работы с run-levels:

```bash
# Узнать текущий run level
runlevel

# Изменить run level (command должна быть выполнена с правами root)
init 3
```

В этом примере init 3 переключит систему в run-level 3.

## 87. Запущенный процесс получает `EAGAIN: Resource temporarily unavailable` при чтении сокета. Как можно закрыть этот плохой сокет/файловый дескриптор без убивания процесса?


В Linux, вы не можете закрыть сокет или файловый дескриптор извне для уже запущенного процесса без убийства процесса.

Операционная система предоставляет функции для работы с дескрипторами файлов и сокетов внутри самого процесса, но не предоставляет возможности манипулировать ими извне.

Обычно, EAGAIN или EWOULDBLOCK означают, что сокет был помечен как неблокирующий, но данные, которые вы хотите прочитать, еще не готовы.

Это не обязательно означает, что с сокетом что-то не так, вы можете просто продолжить попытки чтения с небольшими паузами или использовать механизмы, такие как select, poll или epoll для уведомления о готовности данных к чтению.

## 88. Что такое localhost и почему `ping localhost` может не работать?

Localhost - это специальное имя хоста для IP-адреса машины, на которой работает сетевой сервис, и обычно указывает на "loopback" интерфейс, который имеет IP-адрес 127.0.0.1 в IPv4 или ::1 в IPv6.

Если ping localhost не работает, возможны следующие причины:

Сетевой сервис не настроен или не активен.
Правила файрвола блокируют трафик ICMP, который используется командой ping.
В файле /etc/hosts есть состояние, которое конфликтует с разрешением localhost на IP-адрес loopback.
Настройка localhost в Linux обычно включает две строки в файле /etc/hosts:

```
127.0.0.1   localhost
::1     localhost
```

Если ping localhost не работает, проверьте эти настройки и ваши правила файрвола.


## 89. В чем сходство между "ping" и "traceroute"? Как traceroute находит промежуточные хосты?

"ping" и "traceroute" оба используют протокол ICMP (Internet Control Message Protocol), который используется в системах IP для отправки сообщений об ошибках и операционной информации.

команда "ping" используется для проверки связи между двумя хостами. Он отправляет ICMP Echo Request сообщения с последующими ICMP Echo Reply сообщениями, и время между этими двумя операциями используется для измерения задержки между хостами.

команда "traceroute", в свою очередь, используется для отображения маршрута, который ваш пакет данных следует от одной точки к другой. Здесь ICMP также используется, но совместно с Time To Live (TTL) значениями IP.

"traceroute" находит промежуточные хосты, увеличивая значение TTL от 1 до максимального значения. Всякий раз, когда пакет доходит до хоста (маршрутизатора), TTL уменьшается на 1. Если TTL достигает 0, хост создает сообщение об ошибке ICMP "Time Exceeded" и отправляет его обратно отправителю. "traceroute" использует эти сообщения для определения промежуточных хостов.

traceroute hostname

## 90. Какая команда можно использовать для поиска всех открытых портов и/или соединений с сокетами на машине?


Вы можете использовать команду netstat, которая предоставляет информацию о сетевых соединениях, таблицах маршрутизации и статистике интерфейса.

Для поиска всех открытых портов и активных соединений с сокетами, используйте команду netstat с параметрами -a (все соединения и прослушивающие сокеты) и -n (отображение числовых адресов вместо пытаться определить символьные имена хостов и сервисов):

netstat -an

Если вам нужны более подробные сведения, можно добавить опцию -p для отображения имени программы или PID, который обслуживает каждый сокет:

sudo netstat -anp

sudo netstat -anp
Пожалуйста, обратите внимание: вам может потребоваться установить пакет net-tools, если он не установлен по умолчанию на вашей системе.

## 91. Валидный ли IP адрес 300.168.0.123?


Нет, IP-адрес 300.168.0.123 не является валидным. IPv4 адрес имеет формат 4 блоков цифр, где каждый блок находится в диапазоне от 0 до 255. В указанном адресе 300.168.0.123 первый блок содержит значение 300, которое выходит за допустимый диапазон. Валидным замененом мог бы быть, например, IP-адрес 200.168.0.123.

## 92. Какие IP диапазоны/подсети являются частными или не маршрутизируемыми (RFC 1918)?

```
10.0.0.0 - 10.255.255.255 (10.0.0.0/8)
172.16.0.0 - 172.31.255.255 (172.16.0.0/12)
192.168.0.0 - 192.168.255.255 (192.168.0.0/16)
```

Эти приватные диапазоны предназначены для использования внутри отдельных сетей, таких как домашние, школьные, корпоративные и т.д.

## 93. Что такое VLAN?

VLAN (Virtual Local Area Network) - это технология, которая позволяет одной физической сети делиться на множество изолированных логических сетей. Каждый VLAN образует свою субнеть и обрабатывается сетевым оборудованием, как если бы он был своей отдельной физической сетью. Одной из основных преимуществ использования VLAN является улучшенная безопасность и управление трафиком.

## 94. Что такое ARP и для чего используется?

ARP (Address Resolution Protocol) - это протокол, используемый для отображения IP-адреса на физический (MAC) адрес в локальной сети. Когда устройство хочет отправить пакет другому устройству в локальной сети, оно сначала должно узнать MAC-адрес этого устройства. Если MAC-адрес неизвестен, отправляющее устройство отправит широковещательный ARP-запрос, спрашивая "у кого этот IP-адрес?", а устройство с этим IP-адресом отвечает, предоставляя свой MAC-адрес. После этого отправляющее устройство сможет отправить пакет на нужный MAC-адрес.

## 95. В чем разница между TCP и UDP?

TCP и UDP являются двумя основными протоколами передачи данных в стеке протоколов TCP/IP.

```
TCP (Transmission Control Protocol):
- Гарантирует доставку пакетов данных: если пакет потерян, он будет повторно отправлен.
- Предоставляет функции контроля над ошибками и потоковым управлением.
- Подходит для приложений, где важна надежность и порядок пакетов, например, веб-серверах, электронной почте, базах данных.

UDP (User Datagram Protocol):
- Не гарантирует доставку пакетов данных: если пакет потерян, он не будет повторно отправлен.
- Не предоставляет функции контроля над ошибками и потоковым управлением.
- Подходит для приложений, где важнее скорость, чем надежность, например, видео- и аудиостриминг, онлайн-игры.
```


## 96. Какова цель шлюза по умолчанию?

Шлюз по умолчанию в компьютерных сетях - это узел (обычно маршрутизатор), который система использует для отправки информации на другой компьютер, который не находится в той же подсети. Сказанным другим способом, шлюз по умолчанию служит точкой выхода из локальной сети на другие сети, включая открытый интернет.

## 97. Какая команда используется для просмотра таблицы маршрутизации в Linux?

Команда для просмотра таблицы маршрутизации в Linux - это 'netstat -rn' или 'route -n'. Оба варианта отобразят таблицу маршрутизации ядра.

$ netstat -rn
$ route -n

## 98. TCP-соединение в сети может быть однозначно определено четырьмя вещами. Что это за вещи?

TCP-соединение в сети может быть однозначно определено четырьмя вещами, которые обычно называются "четырьмя кортежами". Они включают следующие элементы:

IP-адрес источника
Порт источника
IP-адрес назначения
Порт назначения
Эта комбинация обеспечивает уникальность TCP-соединения в сети.

## 99. Когда клиент использует бразер для подключения к веб-серверу, какие порты источника и назначения будут у этого соединения?


При подключении клиента к веб-серверу через браузер:

Порт назначения, обычно, будет 80 для HTTP или 443 для HTTPS, так как эти порты стандартно используются для веб-трафика.

Порт источника будет случайным портом выше 1024, который выбирается операционной системой клиента. Этот порт служит для получения ответа от веб-сервера. Он не является статическим и может меняться с каждым новым соединением.

## 100. Как можно добавить IPv6 адрес для конкретного интерфейса?

Вы можете добавить IPv6 адрес для конкретного интерфейса на Linux, используя следующую команду 'ip':

```bash
sudo ip -6 addr add YOUR_IPV6_ADDRESS/64 dev YOUR_INTERFACE_NAME
```

Вам нужно заменить YOUR_IPV6_ADDRESS на нужный IPv6 адрес, а YOUR_INTERFACE_NAME - на имя интерфейса, к которому вы добавляете адрес. Также, 64 - это префикс подсети, вы можете изменить его в соответствие с вашими требованиями.

## 101. Вы добавили IPv4 и IPv6 адреса на eth0 интерфейс. Ping на v4 адрес работает, но ping на v6 адрес дает ответ `sendmsg: operation not permitted`. Что может быть не так?


Эта ошибка обычно происходит при выполнении команды, не имея соответствующих прав или если на вашей системе включен режим защиты. Вот кое-что, что может помочь:

Убедитесь, что вы выполняете команду с правами суперпользователя, используйте sudo перед вашей командой.

Если у вас в системе включен SELinux, это может привести к этой ошибке. Временное отключение SELinux могло бы решить эту проблему. Вы можете временно отключить SELinux командой sudo setenforce 0.

Проверьте ваш firewall, возможно, он блокирует ICMPv6 трафик. Возможно, вам придется разрешить ICMPv6 трафик через ваш firewall.

Пожалуйста, проверьте эти вещи и посмотрите, это решает вашу проблему или нет. Если проблема продолжается, вам может потребоваться более подробная диагностика, чтобы выявить причину.

## 102. Что такое SNAT и когда он должен быть использован?

SNAT означает Source Network Address Translation. Это метод, который используется для преобразования исходного IP-адреса пакетов, проходящих через маршрутизатор или firewall, в другой IP-адрес.

SNAT может быть использован в следующих случаях:

Когда у вас есть приватная сеть, и вы хотите, чтобы все устройства в этой сети имели доступ к интернету через один публичный IP-адрес. SNAT изменяет исходный адрес каждого изходящего пакета, чтобы казалось, что он исходит от публичного IP-адреса.

Когда у вас много серверов с приватными IP-адресами за firewall, и вы хотите балансировать нагрузку между ними. Вы можете настроить SNAT таким образом, чтобы входящий трафик был равномерно распределен между серверами.

Когда нужно перенаправить трафик на другой IP. Например, если у вас есть сервер, который был перемещен на новый IP-адрес, вы можете использовать SNAT для перенаправления трафика с старого IP-адреса на новый.

В общем, SNAT обычно используется, когда вам нужно скрыть исходные IP-адреса или когда вам нужно манипулировать трафиком для достижения определенных результатов.

## 103. Объясните, как можно войти по ssh на Linux сервер, который сбрасывает (DROP) все новые входящие пакеты, используя SSH туннель.


Чтобы установить SSH-соединение с сервером, который сбрасывает все новые входящие пакеты, вы можете установить обратное SSH-туннелирование (Reverse SSH Tunneling). Обратное туннелирование позволяет создать SSH-соединение с удаленным сервером, который инициирует соединение с вашей клиентской машиной, а не наоборот.

Вот как это можно сделать:

На удаленном сервере выполните следующую команду для создания обратного SSH-туннеля к вашей клиентской машине:

```bash
ssh -fN -R 2222:localhost:22 user@client_ip
```

В этой команде:

-fN говорит SSH запуститься в фоновом режиме и не запрашивать ввода команд.

-R 2222:localhost:22 говорит, что необходимо связать порт 2222 на клиентском компьютере с локальным портом 22 на сервере (который используется для SSH).

user@client_ip - это имя пользователя и IP-адрес вашей клиентской машины.

Теперь с вашей клиентской машины вы можете пройти по SSH на ваш сервер, используя созданный туннель:


```bash
ssh -p 2222 localhost
```

Здесь -p 2222 говорит SSH использовать порт 2222 (что было указано при создании туннеля), а localhost ссылается на вашу клиентскую машину, которая теперь слушает порт 2222 для исходящих соединений SSH.

## 104. Как вы будете противодействовать DDoS атаке?


Защита от DDoS-атак - это сложная задача, которая обычно включает в себя несколько стратегий. Вот некоторые из них:

Увеличение пропускной способности: Первым шагом обычно является увеличение пропускной способности вашей сети. Это не решение, но может помочь справиться с малыми или случайными DDoS-атаками.

Использование служб защиты от DDoS: Важно выбрать надежного провайдера услуг безопасности, который может помочь отслеживать и защищать вашу сеть от DDoS-атак.

Заграждение трафика: Одним из способов минимизировать ущерб, нанесенный DDoS-атакой, может быть заграждение трафика, которое отбрасывает трафик от узнаваемых источников DDoS или трафик, который представляет собой явные атаки.

Внедрение правил ограничения частоты: Ограничить скорость, с которой пользователи могут посещать сайт, может помочь предотвратить некоторые DDoS-атаки, предотвращая злоупотребление ресурсами.

Использование CDN: Сети доставки контента (CDN) не только переносят часть вашего трафика, снижая нагрузку на ваши серверы, но и могут помочь отфильтровать злонамеренный трафик.

Планирование: У вас должен быть план действий в случае DDoS-атаки. Данный план включает коммуникацию с командой, провайдером хостинга, уведомление пользователей и другие действия.

Вот пример развертывания правила ограничения частоты с использованием iptables в Linux:

```bash
iptables -A INPUT -p tcp --dport 80 -m limit --limit 50/minute --limit-burst 200 -j ACCEPT
```

Это правило включает ограничение частоты на порту 80, разрешает не более 50 подключений в минуту после первых 200 попыток подключения.





В Linux есть дополнительные инструменты и возможности по защите от DDoS атак:

Firewalls: Усиленная настройка межсетевых экранов Linux, таких как iptables, может создать барьер против DDoS-атак.

Fail2Ban: Это приложение для предотвращения вторжения, которое блокирует IP-адреса, которые имеют определенное количество неудачных попыток входа в систему.

Traffic Control (tc Command): 'tc' - утилита, которая может помочь контролировать сетевой трафик, позволяя вам определить правила, которые ограничивают пропускную способность, задержку и потери пакетов.

sysctl: Использование операционных системных утилит Linux для тонкой настройки поведения сети и ядра.

Log monitoring tools: Инструменты, такие как Logwatch, помогают отслеживать логи системы и тем самым обнаруживать любые аномалии, которые могут указывать на DDoS-атаку.

Вот пример настройки sysctl для изменения поведения TCP/IP стека:

```bash
sysctl net.ipv4.tcp_syncookies=1
sysctl net.ipv4.conf.all.rp_filter=1
sysctl net.ipv4.icmp_echo_ignore_broadcasts=1
```

Включают синхронные cookies для предотвращения SYN flood
Включают RP фильтрацию, отклоняя пакеты с поддельными IP-адресами
Игнорируют ICMP эхо-запросы на широковещательные адреса, чтобы избежать Smurf Attack.


## 105. Как можно посмотреть содержимое ip пакета?


Использование сниффера пакетов, такого как tcpdump или Wireshark, позволит вам захватить и просмотреть содержимое IP-пакетов.

tcpdump - это мощный инструмент командной строки, доступный в большинстве Unix-систем. Следующая команда захватывает пакеты, проходящие через интерфейс ens33, и отображает их содержимое:

```bash
tcpdump -i ens33 -X
```

Здесь:

-i ens33 выбирает сетевой интерфейс для захвата. Замените ens33 на имя интерфейса в вашей системе.
-X говорит tcpdump печатать каждый пакет в hex и ascii.
Wireshark - это графический анализатор протоколов, который предоставляет подробный анализ трафика. Вы можете открыть Wireshark и выбрать сетевой интерфейс для мониторинга. Трафик будет отображаться в реальном времени, а вы сможете подробно изучить каждый пакет.

## 106. Что такое IPoAC (RFC 1149)?

IP over Avian Carriers (IPoAC) - это пропозиция являющаяся шуткой, опубликованная в IETF RFC 1149, которая описывает, как передавать пакеты IP, используя голубей-почтальонов. Была опубликована 1 апреля 1990 года в рамках апрельского прикола. Позже было две обновленные версии этого RFC, включая RFC 2549, IP over Avian Carriers with Quality of Service, и RFC 6214, которое описывает экстеншены для IPv6.


## 107. Как создать пользователя postgresql

```bash
sudo su - postgres # переключиться на пользователя postgres
psql # начать PostgreSQL оболочку

CREATE USER newuser WITH PASSWORD 'password'; # Создание нового пользователя
```

Замените newuser и 'password' на имя пользователя и пароль, которые вы хотите использовать.

## 108. Как предоставить права пользователю postgresql

```bash
sudo su - postgres # Switching to postgres user
psql # Starting PostgreSQL shell

GRANT ALL PRIVILEGES ON database_name TO newuser; # Granting privileges
```

В этом коде замените database_name и newuser на имя базы данных и имя пользователя соответственно. Привилегия ALL дает пользователю все права, включая право на чтение, запись и удаление данных.

## 109. В чем разница между 'left' и 'right' join?

В SQL, LEFT JOIN и RIGHT JOIN используются для объединения двух таблиц. Они отличаются тем, как обрабатываются записи, которые не имеют соответствующих значений в обеих таблицах.

LEFT JOIN: Возвращает все записи из левой таблицы и соответствующие записи из правой таблицы. Если не существует соответствующих значений, результат является NULL с правой стороны.

```sql
SELECT Orders.order_id, Customers.customer_name 
FROM Orders 
LEFT JOIN Customers 
ON Orders.customer_id = Customers.customer_id;
```

RIGHT JOIN: Возвращает все записи из правой таблицы, и соответствующие записи из левой таблицы. Если не существует соответствующих значений, результат является NULL с левой стороны.

```sql
SELECT Orders.order_id, Customers.customer_name 
FROM Orders 
RIGHT JOIN Customers 
ON Orders.customer_id = Customers.customer_id;
```

## 110. Объясните кратко разницу между InnoDB и MyISAM.


nnoDB: Это транзакционная система управления базами данных. Она поддерживает важные функции, такие как внешние ключи для обеспечения ссылочной целостности, транзакции для безопасной обработки данных, и она использует механизм блокировки строк для обеспечения одновременности. InnoDB также обеспечивает устойчивость к сбоям посредством журналов и кеширования данных.

MyISAM: Это система управления базами данных, основанная на не транзакционной модели. Она обеспечивает высокую скорость записи и чтения данных, но у нее нет встроенной поддержки транзакций или внешних ключей. MyISAM использует блокировку таблицы вместо блокировки строк, что может увеличивать скорость операций чтения, но замедлять одновременное выполнение.

В зависимости от требуемой функциональности и производительности, вы можете выбрать тот, который лучше всего подходит для вашего приложения.

## 111. Зачем надо запускать "mysql_secure_installation" после установки MySQL?


mysql_secure_installation это скрипт, который предназначен для выполнения некоторых операций, которые делают вашу установку MySQL безопаснее. Вот некоторые из действий, которые выполняет этот скрипт:

```bash
mysql_secure_installation
```

становка пароля для пользователя root, если его еще нет.
Запрос на удаление анонимных пользователей.
Запрет удаленного входа в систему для пользователя root.
Запрос на удаление базы данных test и доступа к ней.
Применение новых правил и перезагрузка привилегий.
Использование mysql_secure_installation является хорошей практикой после установки MySQL, чтобы позволить системе работать в более безопасной среде.




## 112. Как проверить какие задачи запущены?

Чтобы проверить работающие задачи PostgreSQL, вы можете использовать функцию pg_stat_activity. Она предоставляет информацию о текущем действии каждого сервера процессов PostgreSQL.

Вам нужно будет выдать следующую команду через интерфейс командной строки PostgreSQL или через ваш интерфейс для SQL запросов.

```sql
SELECT * FROM pg_stat_activity;
```

## 113. Как правильно сделать бэкап postgresql в linux

Выполните следующую команду в терминале для бэкапа вашей базы данных PostgreSQL. Замените dbname, username и backup.sql на актуальные значения для вашей конфигурации.

$ pg_dump -U username dbname > backup.sql

Вы можете использовать cron, это распределенная служба в Unix-подобных системах, которая периодически запускает указанные задачи (сценарии). Вы создадите bash-скрипт для бэкапа, а затем добавите его в crontab за запуск в указанное время.

Создайте bash-скрипт.

```bash
#!/bin/bash

PGUSER="username"
PGPASSWORD="password"
DATABASE="database"
BACKUP_DIR="/path/to/your/backup/directory"
FILENAME="backup_`date +%Y%m%d%H%M`.sql"

pg_dump -U $PGUSER $DATABASE > $BACKUP_DIR/$FILENAME
```

Не забудьте заменить "username", "password", "database" и "/path/to/your/backup/directory" на свои реальные значения.

Сделайте скрипт исполняемым.

```bash
chmod +x /path/to/your/script.sh
```

Откройте crontab с помощью команды crontab -e и добавьте следующую строку в файл:

```
0 2 * * * /path/to/your/script.sh
```

Эта строка будет запускать ваш скрипт каждый день в 2:00 утра. Можно изменить время и частоту в соответствии с вашими потребностями.


```python
import os
import subprocess
from datetime import datetime

PGUSER = "username"
PGPASSWORD = "password"
DATABASE = "database"
BACKUP_DIR = "/path/to/your/backup/directory"

filename = "backup_{}.sql".format(datetime.now().strftime('%Y%m%d%H%M'))
backup_file_path = os.path.join(BACKUP_DIR, filename)

command = "pg_dump -U {} {} > {}".format(PGUSER, DATABASE, backup_file_path)

os.putenv('PGPASSWORD', PGPASSWORD)
subprocess.call(command, shell=True)
```

Замените "username", "password", "database" и "/path/to/your/backup/directory" на свои реальные значения. Создайте файл .py, скопируйте и вставьте этот код в файл.

Python script также можно добавить в crontab для периодического выполнения.

```
0 2 * * * /usr/bin/python3 /path/to/your/script.py
```

```go
package main

import (
    "os"
    "os/exec"
    "time"
)

func main() {
    pgUser := "username"
    pgPassword := "password"
    database := "database"
    backupDir := "/path/to/your/backup/directory"

    fileName := "backup_" + time.Now().Format("200601021504") + ".sql"
    backupFilePath := backupDir + "/" + fileName

    cmd := exec.Command("pg_dump", "-U", pgUser, "-f", backupFilePath, database)
    cmd.Env = append(os.Environ(), "PGPASSWORD="+pgPassword)
    err := cmd.Run()

    if err != nil {
        os.Exit(-1)
    }
}
```


Пожалуйста, замените "username", "password", "database" и "/path/to/your/backup/directory" на свои реальные значения.

Вы можете скомпилировать этот скрипт с помощью команды go build /path/to/your/main.go и добавить исполняемый файл в crontab для периодического выполнения:

```
0 2 * * * /path/to/your/executable

```

Эффективность этих сценариев зависит от различных факторов, и их производительность будет очень похожей, так как все они основаны на той же команде pg_dump.

Bash: Bash-скрипт будет быстрым и эффективным, особенно на Unix-подобных операционных системах, так как Bash-команды прямо взаимодействуют с операционной системой.

Python: Python скрипт также будет эффективным, но он может быть немного медленнее, чем Bash-скрипт из-за внутренних операций Python. Однако эта разница обычно не является заметной, особенно для такой простой задачи.

Go: Go создает самостоятельные исполняемые файлы, которые обычно работают быстрее, чем скриптовые языки, такие как Python или Bash. Но снова, для данной задачи разница будет небольшой.

Если вы рассматриваете производительность в контексте, сколько ресурсов используется для запуска скрипта, это будет зависеть от вашей конкретной системы, на которой запущены скрипты. Однако, в целом, эти три скрипта не будут иметь значительных отличий в плане использования ресурсов.

Более важным фактором при выборе между этими языками может быть удобство поддержки и чтения кода, а также предпочтения и навыки разработчика.


Нет, crontab - это не единственный способ автоматизации задач в Linux. Есть некоторые другие методы, которые применяются для автоматизации задач:

Systemd timers: Systemd - это системный и служебный менеджер для Linux, который поддерживает программирование и автоматизацию задач с помощью timers. Он более гибкий чем cron и предоставляет больше информации о сбоях и истории выполнения задач.

Anacron: Если ваша система не работает 24/7, тогда Anacron может быть лучшей альтернативой. Он идеально подходит для систем, которые не работают всегда, потому что он выполняет задачи по расписанию даже если система была выключена в назначенное время.

at and batch команды: Эти команды позволяют запланировать задачи, которые будут выполнены единожды. at выполняет задачу в определенное время, а batch выполняет задачу, когда уровень загрузки системы падает ниже определенного значения.

incron: Это система мониторинга "inotify", которая позволяет запускать команды или скрипты в ответ на изменения в файлах или директориях. Это может быть полезно для задач, зависящих от изменения файлов, вместо времени.

Выбор подходящего способа зависит от ваших конкретных потребностей.

## 114. Как использовать systemd timers
Чтобы использовать systemd timers для выполнения задач, вам нужно создать два файла: файл службы и файл таймера.

Рассмотрим пример, как можно использовать это для бэкапа базы данных Postgres.

Создайте файл службы, например, /etc/systemd/system/backup_postgres.service

```
[Unit]
Description=Backup PostgreSQL database

[Service]
ExecStart=/usr/local/bin/backup_postgres.sh
```

В этом файле мы задаем команду, которую нужно выполнить.

Создайте файл /usr/local/bin/backup_postgres.sh и сделайте его исполняемым.

```bash
#!/bin/bash
# Replace 'my_database', 'username', '/path/to/backup/dir/' according to your Postgres setup
pg_dump my_database -U username -f /path/to/backup/dir/my_database.bak
```

Сделайте файл исполняемым:

```bash
sudo chmod +x /usr/local/bin/backup_postgres.sh
```

Создайте файл таймера, например, /etc/systemd/system/backup_postgres.timer.

```
[Unit]
Description=Run backup_postgres.service every day

[Timer]
OnCalendar=daily
Persistent=true

[Install]
WantedBy=timers.target
```

Этот таймер будет запускать бэкап ежедневно.

Запустите и включите таймер:

```bash
sudo systemctl start backup_postgres.timer
sudo systemctl enable backup_postgres.timer
```

Вы можете проверить статус таймера:

```bash
systemctl list-timers
```

Вот несколько причин, почему вы можете выбрать systemd timers вместо cron:

Логирование: systemd предоставляет единый и систематический подход к логированию, что может быть полезно.
Гибкость: systemd timers более гибкий при задании времени выполнения.
Управление зависимостями: systemd управляет зависимостями между различными службами и единицами.
Задержка в запуске: systemd timers позволяет настроить проваливание, если предыдущий запуск еще не завершен.
Тем не менее, cron все еще является полезным и наилучшим выбором для некоторых сценариев, особенно из-за своей простоты.

В зависимости от вашего конкретного случая, один из инструментов может подойти лучше другого.

## 115. Как вы можете описать ваш workflow при создании скрипта?

1. Разбор входных требований, набросок основного плана.
2. Создание основной логики кода.
3. Процесс тестирования кода на ошибки и их исправления.
4. Оптимизация путем рефакторинга кода для улучшения производительности. 
5. Конечная проверка соответствия выходного кода входным требованиям.

Следует отметить, что этот процесс может варьироваться и/или быть итерационным в зависимости от сложности задачи и требований.


## 116. Что такое GIT?

Git - это система управления версиями, которую можно использовать для отслеживания изменений в файлах и работе с ними в команде. Она основана на архитектуре "распределенной системы управления версиями", при которой каждый разработчик имеет полную копию истории проекта на своем компьютере. Это позволяет иметь высокую скорость работы, гибкость в управлении ветками и облегчает отслеживание изменений.

Важные функции Git включают в себя:

Branching (ветвление) и Merging (слияние) - Это позволяет разработчикам легко создавать и объединять ветки для работы над отдельными фичами.
Стейджинг и коммиты - Git позволяет разработчикам отслеживать и отменять изменения.
Лог истории изменений - Позволяет видеть предыдущие изменения и кому они принадлежат.
Работа в команде - Git поддерживает разработку в команде и позволяет синхронизировать изменения между несколькими разработчиками.
Работа с удаленными репозиториями - Git поддерживает работу с удаленными репозиториями, что позволяет хранить код в безопасности и совместно работать со своими коллегами.

```bash
# Клонирование удаленного репозитория
git clone <url>

# Создание новой ветки
git branch <branch_name>

# Переключение на ветку
git checkout <branch_name>

# Добавление файлов в стейдж
git add <file_name>

# Создание нового коммита
git commit -m "<commit_message>"

# Отправка изменений в удаленный репозиторий
git push origin <branch_name>

# Получение изменений из удаленного репозитория
git pull origin <branch_name>  

# Смотреть историю коммитов
git log
```

## 117. Что такое динамически/статически слинкованные файлы?

Статическая и динамическая линковка относятся к тому, как программы взаимодействуют с библиотеками в операционной системе.

Статическая линковка: Библиотеки статически подключаются к исполняемому файлу на стадии компиляции. Результатом является один большой исполняемый файл, который включает в себя всю функциональность библиотек. Это упрощает развертывание, так как нет зависимости от внешних библиотек, но это увеличивает размер исполняемого файла.

Динамическая линковка: Исполняемый файл содержит ссылки на библиотеки, которые подключаются на стадии выполнения программы. Это позволяет нескольким программам делить одну и ту же библиотеку в памяти, уменьшая общий размер программ и сохраняя ресурсы. Однако, эта программа теперь зависит от этих внешних библиотек, и они должны быть доступны в операционной системе на стадии выполнения.

## 118. Что делает "./configure && make && make install"?


./configure && make && make install - это последовательность команд, обычно используемых в процессе сборки и установки программного обеспечения из исходного кода в Unix-подобных системах.

./configure: Эта команда готовит компоновку исходного кода программы, настраивая переменные среды и определяя, какие компоненты необходимы для сборки. Например, проверяя установленные библиотеки, создает makefile в соответствии с вашим хост-средой (операционная система, архитектура процессора и т. д.).

make: Команда make используется для сборки и компиляции исходного кода в исполняемый файл с использованием makefile, созданного ./configure.

make install: Эта команда используется для установки программы в систему после успешной компиляции. Обычно это включает в себя копирование исполняемых файлов, библиотек и руководств в соответствующие каталоги системы. Обратите внимание, что для этой команды обычно требуются административные привилегии.

```bash
./configure
make
sudo make install
```

Приведенная строка использует оператор && для соединения команд, так что последующая команда выполняется только в том случае, если предыдущая команда завершилась успешно.


## 119. Для чего используется puppet/chef/ansible?


Puppet, Chef и Ansible являются инструментами для автоматической настройки и управления системными ресурсами, часто используемыми в области DevOps для "инфраструктуры как кода". Их основное назначение:

Puppet: Он предлагает гибкое, мощное и кросс-платформенное решение для управления конфигурациями. Puppet использует собственный декларативный язык или Ruby для записи конфигураций.

Chef: Chef работает на языке Ruby и предлагает набор инструментов для разработчиков и системных администраторов, чтобы настройка, развертывание и управление серверами были кодифицированы и автоматизированы.

Ansible: Ansible - это система управления конфигурациями, написанная на Python, которая использует декларативный язык YAML для описания системной конфигурации. Особенностью Ansible является его низкий порог входа и простота использования. Ansible не требует установки агентов на управляемых узлах, что упрощает развертывание.

Все три инструмента предоставляют модули или рецепты, которые можно использовать для автоматической установки и настройки программного обеспечения в двух направлениях. Это полезно, когда у вас есть множество серверов и вы хотите, чтобы они все были настроены одинаково.

## 120. Для чего используется Nagios/Zenoss/NewRelic?

Nagios, Zenoss и NewRelic - это инструменты мониторинга, используемые для отслеживания состояния IT-инфраструктуры и/или приложений.

Nagios: Это открытое программное обеспечение, используемое для мониторинга систем, сетей и инфраструктуры. Он сообщает о проблемах, связанных с доступностью, ответом, ускорением и другими метриками IT-среды.

Zenoss: Этот инструмент обеспечивает мониторинг оборудования, операционных систем, сетей и приложений. Он использует Zope и Python для своей работы, и он предлагает пользовательский графический интерфейс для просмотра и настройки информации о мониторинге.

NewRelic: New Relic - это SaaS-платформа для мониторинга производительности приложений (APM). Она ориентирована на мониторинг веб-приложений и служб, работающих в облаке, предлагая инструменты для анализа производительности и отладки кода приложений.

## 121. Для чего используется Jenkins/TeamCity/GoCI?

Jenkins, TeamCity и GoCD - это инструменты для непрерывной интеграции и доставки (CI/CD), которые помогают автоматизировать процесс разработки программного обеспечения.

Все три инструмента автоматизируют сборку, тестирование и развертывание кода при каждом изменении, помогая командам быстро выявлять и исправлять проблемы с кодом и ускорить процесс доставки программного обеспечения. Они помогают внедрять практики непрерывной интеграции и доставки.

## 122. В чем разница между контейнеризацией и виртуализацией?


Контейнеризация и виртуализация - это два подхода к изоляции ресурсов, но они работают на разных уровнях.

Виртуализация эмулирует аппаратное обеспечение для создания множества виртуальных машин (VM), каждая из которых может выполнять собственную операционную систему. Это позволяет разделить одну физическую машину на несколько виртуальных машин, каждая из которых работает как отдельный компьютер со своими собственными операционными системами и приложениями.


С другой стороны, контейнеризация работает на уровне операционной системы, общая одна и та же ОС между контейнерами, но изолируя приложения и их зависимости друг от друга в отдельных "контейнерах". Это делает контейнеры более легкими и более быстрыми для запуска, чем виртуальные машины, поскольку они не требуют дополнительной нагрузки целых операционных систем.

В общем, выбор между контейнеризацией и виртуализацией будет зависеть от ваших конкретных требований, таких как уровень изоляции, безопасности, производительности и совместимости.



## 123. Как создать нового postgres пользователя?

Вы можете создать нового пользователя (обычно называемого "ролью") в Postgres, используя следующий SQL-команды:

```sql
CREATE USER your_new_user WITH PASSWORD 'your_password';

-- To give this user superuser privileges:
ALTER USER your_new_user WITH SUPERUSER;

-- OR to give this user ability to create databases:
ALTER USER your_new_user CREATEDB;
```

Примечание: эти команды нужно запустить в среде оболочки SQL, такой как psql от администратора базы данных или пользователя с соответствующими привилегиями.


## 124. Что такое виртуальный IP адрес? Что такое кластер?


Виртуальный IP-адрес (VIP) - это адрес, который не связан с определенным физическим сетевым интерфейсом (NIC). Обычно VIP используется в сценариях балансировки нагрузки или отказоустойчивости. В этих случаях несколько устройств имеют один и тот же IP-адрес, и сетевой трафик, предназначенный для этого IP-адреса, будет направлен на одно из этих устройств. Если одно устройство выходит из строя, другое устройство автоматически начнет обрабатывать трафик.

Кластер в компьютерной терминологии - это группа серверов и других ресурсов, которые действуют как единый системный ресурс. Кластеры используются для обеспечения повышенной доступности, отказоустойчивости и/или улучшения производительности. Например, в кластере базы данных может быть несколько серверов, каждый из которых может обслуживать запросы к базе данных. Если один сервер выходит из строя, другой сервер в кластере может продолжить обрабатывать запросы без прерывания работы.

## 125. Как вывести все строки печатных символов, присутствующих в файле?


Для вывода всех строк печатных символов, присутствующих в файле, вы можете использовать команду strings. Это стандартная команда Unix/Linux, которая выводит печатные строки из файла.

```bash
strings filename
```

## 126. Как найти зависимости для библиотеки?

Если вы хотите просмотреть зависимости для конкретной библиотеки в Linux, вы можете использовать команду ldd:

```bash
ldd /path/to/your/library.so
```

Замените /path/to/your/library.so на путь к библиотеке, и эта команда покажет все библиотеки, от которых она зависит.
## 127. Что такое Automake и Autoconf?

autoconf и automake являются частью набора инструментов GNU Build System, который часто используется для управления процессом сборки и установки программного обеспечения в Unix-подобных операционных системах.

autoconf - это инструмент, который генерирует скрипты оболочки, которые автоматически настраивают программное обеспечение для компиляции на Unix-подобных системах.

Пример использования можно увидеть ниже:

```bash
autoconf configure.ac > configure
```

Здесь configure.ac это входной файл, содержащий макросы autoconf, а configure - это созданный скрипт, который будет использоваться для настройки программного обеспечения перед компиляцией.

automake, с другой стороны, это инструмент, который генерирует Makefile.in файлы из Makefile.am файлов. Makefile.am является входным файлом, который содержит информацию, в основном состоящую из тех же списков источников и целей, что и обычные Makefile'ы.

Пример использования можно увидеть ниже:

```bash
automake --add-missing
```

Эта команда создаст Makefile.in из Makefile.am.

В комбинации эти инструменты позволяют создавать переносимые процессы сборки, которые могут автоматически адаптироваться к различным системам.

## 128. ./configure вывела ошибку, что libfoobar не найдена в система, как вы будете исправлять это? Что может быть не так?

Ошибка, которую вы видите, говорит о том, что библиотека libfoobar не найдена в вашей системе. Это может быть вызвано одной или несколькими причинами, такими как: библиотека не установлена, установлена не та версия библиотеки, или путь к библиотеке не присутствует в переменной окружения LD_LIBRARY_PATH.

Чтобы исправить это, сначала убедитесь, что libfoobar установлена в системе. С помощью менеджера пакетов в вашем дистрибутиве Linux установите libfoobar, если он отсутствует. Например, если вы используете Ubuntu или Debian, вы могли бы использовать следующую команду для установки:


```bash
sudo apt-get install libfoobar-dev
```

Если библиотека уже установлена, проверьте, обнаруживается ли она системой, используя ldconfig:

```bash
ldconfig -p | grep foobar
```

Если библиотека установлена и все же не обнаруживается, возможно, будет необходимо обновить переменную окружения LD_LIBRARY_PATH и указать путь к libfoobar. Если, например, библиотека установлена в /usr/local/lib, выполните следующую команду:


``` 
export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
```

Убедитесь, что вы заменяете /usr/local/lib на путь, где действительно установлена libfoobar.

После того как вы прошли все эти шаги, повторите попытку выполнить ./configure. Если все было сделано правильно, ./configure должен завершиться без ошибок.


## 129. Какие преимущества/недостатки у скриптов против компилируемых программ?


Преимущества скриптов:

Простота: Скрипты обычно более просты для чтения и написания, особенно для несложных задач.
Портабельность: Если скрипт написан на переносимом языке (например, Python или Perl), он может выполняться практически на любой платформе без необходимости изменения или компиляции.
Быстрая разработка и отладка: Итоговый скрипт можно протестировать и отладить сразу же после написания.
Недостатки скриптов:

Производительность: Скрипты обрабатываются с помощью интерпретатора, что обычно делает их менее эффективными по сравнению с компилируемыми программами.
Зависимость от интерпретатора: Для выполнения скрипта на машине должен быть установлен соответствующий интерпретатор.
Преимущества компилируемых программ:

Производительность: Компилируемые программы в общем случае быстрее, так как они преобразуются в машинный код, который затем непосредственно исполняется процессором.
Оптимизация: Компиляторы могут применять оптимизации во время сборки, чтобы улучшить производительность и эффективность использования ресурсов.
Безопасность: Компилируемым программам труднее взломать или изменить, поскольку их исходный код не доступен в открытом виде.
Недостатки компилируемых программ:

Сложность: Писать, компилировать и отлаживать компилируемые программы может быть сложнее, особенно для сложных систем.
Портабельность: Компилируемые программы обычно требуют перекомпиляции для каждой целевой платформы.
Время разработки: Процесс компиляции занимает время, что увеличивает время разработки.


## 130. Какая связь между непрерывной доставкой (continuous delivery) и DevOps?


Непрерывная доставка (Continuous Delivery, CD) и DevOps являются взаимосвязанными практиками, которые используются в современных подходах к разработке программного обеспечения.

DevOps – это культура и подход к разработке ПО, который усиливает сотрудничество между командами разработки (Dev) и операций (Ops), ускоряя и оптимизируя процесс доставки ПО.

Непрерывная доставка – это DevOps-практика, направленная на постоянное создание, тестирование и подготовку к выпуску кода с целью обеспечения возможности скорейшего и безопасного выпуска новых версий приложений.

В реализации DevOps непрерывная доставка обычно связана с такими практиками, как непрерывная интеграция (Continuous Integration, CI), непрерывное тестирование и непрерывное развертывание. Эти практики сохраняют программное обеспечение постоянно готовым к выпуску, уменьшают риск появления ошибок и ускоряют цикл обратной связи.


## 131. Каковы важные аспекты системы непрерывной интеграции и развертывания


Система непрерывной интеграции и развертывания (Continuous Integration and Deployment, CI/CD) основывается на нескольких важных аспектах:

Непрерывная интеграция (CI): Это практика регулярного слияния кода, написанного разработчиками, в общий репозиторий. После слияния код автоматически тестируется. CI помогает быстро обнаруживать и исправлять ошибки.

Непрерывная доставка (CD): Это процесс автоматической установки всех обновлений кода в тестовые и продуктовые среды после прохождения тестирования.

Непрерывное развертывание (также CD): Это дальнейшее продолжение процесса непрерывной доставки, в котором обновления автоматически развертываются на продуктивной среде без вмешательства человека.

Автоматизированное тестирование: Важная составляющая CI/CD, которая обеспечивает качество кода и отсутствие регрессии.

Инфраструктура как код (IaC): Это практика управления и организации инфраструктуры через код, что позволяет автоматизировать развертывание.

Мониторинг и логирование: Беспрерывный сбор данных о работе системы и её поведении важен для оперативного обнаружения и исправления проблем.

Безопасность: В процесс CI/CD должны быть встроены механизмы обеспечения безопасности, включая сканирование на наличие уязвимостей и автоматическое обновление патчей безопасности.

Цель использования CI/CD - ускорить процесс разработки и упростить управление изменениями, позволяя командам быстрее и эффективнее отвечать на потребности бизнеса.


## 132. Как бы вы включили совместное использование сетевых файлов в AWS, которые позволили бы экземплярам EC2 в нескольких зонах доступности обмениваться данными?


Для совместного использования сетевых файлов между экземплярами EC2 в разных зонах доступности на AWS вы можете использовать сервис от AWS под названием Amazon Elastic File System (EFS) который обеспечивает простую масштабируемую файловую систему. Здесь приведены основные шаги для ее настройки:

Вы начинаете с создания файловой системы EFS в AWS Management Console.

```bash
aws efs create-file-system --creation-token MyCreationToken
```

Затем вы создаете точки монтирования в нужных вам зонах доступности.

```bash
aws efs create-mount-target --file-system-id fs-01234567 --subnet-id subnet-0123456a --security-groups sg-0123456a
```

После создания файловой системы EFS и точек монтирования, вы можете монтировать файловую систему на ваши экземпляры EC2, используя стандартные инструменты Linux для работы с файловыми системами.

```bash
sudo mount -t nfs -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-01234567.efs.us-west-2.amazonaws.com:/ /mnt/efs
```


Чтобы файловая система автоматически монтировалась при перезагрузке, добавьте запись в файл /etc/fstab.

```bash
echo 'fs-01234567.efs.us-west-2.amazonaws.com:/ /mnt/efs nfs defaults,vers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 0 0' | sudo tee -a /etc/fstab
```

Каждый экземпляр EC2 может читать и записывать файлы в общем EFS, делая его отличным решением для обмена данными между экземплярами в разных зонах доступности.



## 133. Небрежный сисадмин запустил команду `chmod 444 /bin/chmod` - как будете исправлять проблему?



Если сисадмин случайно установил привилегии chmod 444 на /bin/chmod, он отберет у файловое право на исполнение. Чтобы исправить это, можно использовать cp (копирование) или mv (перемещение) для восстановления исполняемых прав доступа.

```bash
# сначала копируем файл chmod во временную папку
cp /bin/chmod /tmp

# затем меняем права доступа к временно копированному файлу
/bin/chmod 755 /tmp/chmod

# затем заменяем исходный файл из временной папки
mv /tmp/chmod /bin/chmod
```

Таким образом, мы восстановили права на исполнение для /bin/chmod.


## 134. Я потерял пароль пользователя root. Что мне делать?

Если вы потеряли пароль от root на Linux сервере, вы можете сбросить его, перезагрузив систему в режиме восстановления (recovery mode) или в процессе загрузки изменить параметры для grub. Вот основные шаги:

Перезагрузите систему. Обычно это можно сделать, нажав Ctrl+Alt+Del или reboot в командной строке, если у вас есть доступ.
При появлении экрана загрузчика GRUB нажмите e, чтобы войти в режим редактирования.
Найдите строку начинающуюся с linux или linux16. Она обычно включает в себя параметры загрузки ядра.
В конце этой строки, добавьте rw init=/bin/bash.
Нажмите Ctrl+x или F10, чтобы начать загрузку в этом режиме.
Система загрузится в режиме суперпользователя без запроса пароля. Теперь вы можете сменить пароль root с помощью команды passwd.
После этого уведите систему просто набрав команду reboot и у вас будет новый пароль root.
Пожалуйста, обратите внимание, что этот подход работает только если на сервере не установлено зашифрованное ядро или пароль на загрузчик.

## 135. Я перезагрузил удаленный сервер, но спустя 10 минут все еще не могу зайти по SSH. Что может быть не так?



Есть множество причин, по которым удаленный сервер может быть недоступен через SSH после перезагрузки. Вот некоторые распространенные проблемы:

Сервер еще не завершил перезагрузку. В некоторых случаях, особенно если на сервере работают сложные процессы или его конфигурация, перезагрузка может занять больше времени, чем обычно.

Сервис SSH не запустился. По разным причинам, SSH может не стартовать при загрузке. Это может быть из-за ошибок в конфигурации SSH, неправильных прав доступа на ключи SSH или проблем с файловой системой.

Сетевые проблемы. Если сеть сервера не работает, то SSH не сможет получить доступ. Это может быть результатом проблем с настройками сети сервера, сбоя вашего интернет-провайдера или проблемы сети в центре данных

## 136. Вы случайно удалили запущенный скрипт, как вы будете его восстанавливать?


Если вы случайно удалили уже запущенный скрипт, не беспокойтесь, его можно восстановить. В Linux, если процесс всё ещё работает, у вас всё ещё есть ссылка на файл через файловую систему /proc.

```bash
# Допустим, PID вашего скрипта - 1234
cp /proc/1234/exe /path/to/restored/script
```

Обратите внимание, этот метод не будет работать, если скрипт уже завершил свою работу.

Также важно помнить о резервном копировании важных файлов и скриптов, чтобы восстановить их в случае потери или случайного удаления.

## 137. Распакуйте test.tar.gz

tar -xzf test.tar.gz

## 138. Удалите все "*.pyc" файлы рекурсивно из testdir.

```bash
find testdir -name '*.pyc' -type f -delete
```

Эта команда найдет и удалит все файлы с расширением .pyc в каталоге testdir и его подкаталогах.

## 139. Найдите все "my konfu is the best" во всех *.py файлах.

grep -r --include=*.py "my konfu is the best"

Эта команда выполнит рекурсивный поиск строки "my konfu is the best" во всех файлах с расширением .py.

## 140. Замените все вхождения "my konfu is the best" на "I'm a linux jedi master" во всех *.txt файлах.

```bash
find . -name "*.txt" -type f -exec sed -i 's/my konfu is the best/I'\''m a linux jedi master/g' {} \;
```

Эта команда найдет все файлы с расширением .txt и заменит каждое вхождение строки "my konfu is the best" на "I'm a linux jedi master".


## 141. Проверьте доступность 443 порта на машине с IP X.X.X.X.

```bash
nc -zv X.X.X.X 443
```

## 142. Получите страницу [http://myinternal.webserver.local/test.html](http://myinternal.webserver.local/test.html) при помощи telnet.

```bash

telnet myinternal.webserver.local 80
```

```bash
GET /test.html HTTP/1.1
Host: myinternal.webserver.local
Connection: close
```


## 143. Как отправить email без почтового клиента, только с помощью командной строки?

```bash
echo "Содержимое письма" | mail -s "Тема письма" email@example.com
```

Эта команда отправит email из командной строки. Замените "Содержимое письма", "Тема письма" и "email@example.com" на соответствующие значения. Для использования этой команды, mailx (или mail) должна быть установлена на вашей системе.


## 144. Напишите метод `get_prim` в python/perl/bash/pseudo.


```python
def get_prime(n):
    primes = []
    chk = 2
    while len(primes) < n:
        ptest = [chk for i in primes if chk%i == 0]
        primes += [] if ptest else [chk]
        chk += 1
    return primes

print(get_prime(10))

```

## 145. Найдите все файлы, доступ к которым был осуществлен за последние 30 дней.

```bash
find /path/to/search/ -type f -atime -30
```

## 146. Объясните следующую команду `(date ; ps -ef | awk '{print $1}' | sort | uniq | wc -l ) >> Activity.log`


Эта команда записывает количество уникальных пользователей, выполняющих процессы в системе, вместе с текущей датой и временем в файл Activity.log.

date: Получает текущую дату и время.
ps -ef: Выводит все текущие процессы в системе.
awk '{print $1}': Из каждой строки вывода ps -ef берет первый столбец (обычно это пользователя, который запустил процесс).
sort: Сортирует результат, производимый предыдущей командой.
uniq: Удаляет все дубликаты из отсортированного списка, оставляя только уникальные значения.
wc -l: Считает количество строк в результирующем списке, что будет равно количеству уникальных пользователей.
>> Activity.log: Записывает выходные данные всего вышеуказанного пайплайна в файл `Activity.log

## 147. Напишите скрипт, показывающий разницу двух каталогов.

